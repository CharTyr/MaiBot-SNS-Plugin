"""
MaiBot_SNS - ç¤¾äº¤å¹³å°ä¿¡æ¯é‡‡é›†ä¸è®°å¿†å†™å…¥æ’ä»¶

é€šè¿‡MCPæ¡¥æ¥è°ƒç”¨ç¤¾äº¤å¹³å°APIï¼ˆå¦‚å°çº¢ä¹¦ï¼‰ï¼Œé‡‡é›†å†…å®¹å¹¶å†™å…¥ChatHistoryè®°å¿†ç³»ç»Ÿã€‚
æ”¯æŒåšæ¢¦æ¨¡å—é›†æˆã€å®šæ—¶ä»»åŠ¡å’Œæ‰‹åŠ¨å‘½ä»¤è§¦å‘ã€‚
"""

import asyncio
import json
import os
import time
from dataclasses import asdict, dataclass, field
from pathlib import Path
from typing import List, Tuple, Type, Optional, Dict, Any

from src.plugin_system import (
    BasePlugin,
    BaseCommand,
    BaseTool,
    ComponentInfo,
    ConfigField,
    ToolParamType,
    register_plugin,
    get_logger,
)
from src.plugin_system.base.config_types import ConfigSection
from src.plugin_system.base.base_events_handler import BaseEventHandler
from src.plugin_system.base.component_types import EventType
from src.plugin_system.base.component_types import PythonDependency
from src.plugin_system.apis import tool_api, llm_api, database_api
from src.common.database.database_model import ChatHistory

logger = get_logger("maibot_sns")

def _get_data_dir() -> Path:
    """è·å–æ’ä»¶è¿è¡Œæ—¶å¯å†™ç›®å½•ï¼ˆé»˜è®¤ data/maibot_snsï¼Œå¯ç”¨ç¯å¢ƒå˜é‡è¦†ç›–ï¼‰ã€‚"""
    env_dir = os.getenv("MAIBOT_SNS_DATA_DIR", "").strip()
    if env_dir:
        return Path(env_dir)
    return Path("data") / "maibot_sns"


def _ensure_data_dir() -> Path:
    data_dir = _get_data_dir()
    try:
        data_dir.mkdir(parents=True, exist_ok=True)
    except Exception:
        pass
    return data_dir


# è¿è¡Œæ—¶æ–‡ä»¶è·¯å¾„ï¼ˆä¸¥ç¦å†™å…¥æ’ä»¶ç›®å½•ï¼‰
DATA_DIR = _ensure_data_dir()
CACHE_FILE = DATA_DIR / "failed_writes.json"
STATE_FILE = DATA_DIR / "collector_state.json"


def _load_state() -> Dict[str, Any]:
    """åŠ è½½æ’ä»¶çŠ¶æ€ï¼ˆé¢„è§ˆç¼“å­˜ç­‰ï¼‰ã€‚"""
    if STATE_FILE.exists():
        try:
            return json.loads(STATE_FILE.read_text(encoding="utf-8"))
        except Exception:
            return {}
    return {}


def _save_state(state: Dict[str, Any]) -> None:
    """ä¿å­˜æ’ä»¶çŠ¶æ€ï¼ˆé¢„è§ˆç¼“å­˜ç­‰ï¼‰ã€‚"""
    try:
        _ensure_data_dir()
        STATE_FILE.write_text(json.dumps(state, ensure_ascii=False, indent=2), encoding="utf-8")
    except Exception as e:
        logger.warning(f"ä¿å­˜çŠ¶æ€å¤±è´¥: {e}")


def _normalize_config(config: Any) -> Dict[str, Any]:
    """å°†åŒ…å«ç‚¹å·é”®çš„é…ç½®å½’ä¸€åŒ–ä¸ºåµŒå¥— dictï¼Œå…¼å®¹å¤šç§ config ç»“æ„ã€‚"""
    if not isinstance(config, dict):
        return {}

    def deep_merge(dst: Dict[str, Any], src: Dict[str, Any]) -> Dict[str, Any]:
        for k, v in src.items():
            if k in dst and isinstance(dst[k], dict) and isinstance(v, dict):
                deep_merge(dst[k], v)
            else:
                dst[k] = v
        return dst

    def set_dotted(dst: Dict[str, Any], dotted_key: str, value: Any) -> None:
        parts = [p for p in dotted_key.split(".") if p]
        if not parts:
            return
        cur = dst
        for p in parts[:-1]:
            if p not in cur or not isinstance(cur.get(p), dict):
                cur[p] = {}
            cur = cur[p]
        cur[parts[-1]] = value

    out: Dict[str, Any] = {}
    for k, v in config.items():
        v_norm = _normalize_config(v) if isinstance(v, dict) else v
        if isinstance(k, str) and "." in k:
            set_dotted(out, k, v_norm)
        else:
            if k in out and isinstance(out.get(k), dict) and isinstance(v_norm, dict):
                deep_merge(out[k], v_norm)  # type: ignore[arg-type]
            else:
                out[k] = v_norm
    return out

# å…¨å±€çŠ¶æ€ï¼ˆç”¨äº WebUI å’Œç»Ÿè®¡ï¼‰
_collector_stats: Dict[str, Any] = {
    "last_collect_time": 0,
    "total_collected": 0,
    "total_written": 0,
    "total_filtered": 0,
    "total_duplicate": 0,
    "last_result": None,
    "is_running": False,
    "recent_memories": [],  # æœ€è¿‘å†™å…¥çš„è®°å¿†
}

# feed_id ç¼“å­˜ï¼ˆé¿å…é‡å¤æŸ¥è¯¢æ•°æ®åº“ï¼‰ï¼Œå­˜å‚¨æ ¼å¼: "{platform}:{feed_id}"
_feed_id_cache: set = set()
_feed_id_cache_loaded: bool = False


# ============================================================================
# æ•°æ®æ¨¡å‹
# ============================================================================

@dataclass
class SNSContent:
    """ç¤¾äº¤å¹³å°å†…å®¹ï¼ˆé€šç”¨æ ¼å¼ï¼‰"""
    feed_id: str           # å†…å®¹å”¯ä¸€æ ‡è¯†
    platform: str          # å¹³å°åç§°
    title: str             # æ ‡é¢˜
    content: str           # æ­£æ–‡å†…å®¹
    author: str            # ä½œè€…
    like_count: int = 0    # ç‚¹èµ/å–œæ¬¢æ•°
    comment_count: int = 0 # è¯„è®ºæ•°
    image_urls: List[str] = field(default_factory=list)  # å›¾ç‰‡åˆ—è¡¨
    url: str = ""          # åŸæ–‡é“¾æ¥
    extra: Dict[str, Any] = field(default_factory=dict)  # é¢å¤–æ•°æ®ï¼ˆå¹³å°ç‰¹å®šï¼‰


@dataclass
class CollectResult:
    """é‡‡é›†ç»“æœ"""
    success: bool
    fetched: int = 0
    written: int = 0
    filtered: int = 0
    duplicate: int = 0
    errors: List[str] = field(default_factory=list)
    preview_contents: List[Dict] = field(default_factory=list)  # é¢„è§ˆå†…å®¹
    preview_items: List[SNSContent] = field(default_factory=list, repr=False)  # é¢„è§ˆæ¡ç›®ï¼ˆç”¨äºç¡®è®¤å†™å…¥ï¼‰
    
    def summary(self) -> str:
        status = "âœ…" if self.success else "âŒ"
        return f"{status} è·å–:{self.fetched} å†™å…¥:{self.written} è¿‡æ»¤:{self.filtered} é‡å¤:{self.duplicate}"


# ============================================================================
# å¹³å°é€‚é…å™¨ï¼ˆæ”¯æŒå¤šå¹³å°æ‰©å±•ï¼‰
# ============================================================================

class PlatformAdapter:
    """å¹³å°é€‚é…å™¨åŸºç±» - å®šä¹‰å¦‚ä½•è§£æä¸åŒå¹³å°çš„æ•°æ®"""
    
    platform_name: str = "generic"
    
    # å·¥å…·åæ˜ å°„ï¼ˆå¯åœ¨é…ç½®ä¸­è¦†ç›–ï¼‰
    default_tools = {
        "list": "list_feeds",      # è·å–åˆ—è¡¨
        "search": "search_feeds",  # æœç´¢
        "detail": "get_feed_detail",  # è·å–è¯¦æƒ…
    }
    
    # å­—æ®µæ˜ å°„ï¼ˆä» MCP è¿”å›æ•°æ®æ˜ å°„åˆ° SNSContentï¼‰
    field_mapping = {
        "feed_id": ["id", "note_id", "feed_id", "item_id"],
        "title": ["title", "displayTitle", "name", "headline"],
        "content": ["content", "desc", "description", "text", "body"],
        "author": ["author", "nickname", "user.nickname", "user.name", "creator"],
        "like_count": ["likedCount", "like_count", "likes", "interactInfo.likedCount"],
        "comment_count": ["commentCount", "comment_count", "comments", "interactInfo.commentCount"],
        "images": ["images", "imageList", "image_list", "cover", "pics"],
        "url": ["url", "link", "webUrl", "share_url"],
    }
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        # å…è®¸é…ç½®è¦†ç›–é»˜è®¤æ˜ å°„
        custom_mapping = config.get("field_mapping", {})
        if custom_mapping:
            self.field_mapping = {**self.field_mapping, **custom_mapping}
        custom_tools = config.get("tools", {})
        if custom_tools:
            self.default_tools = {**self.default_tools, **custom_tools}
    
    def _get_nested_value(self, data: Dict, path: str) -> Any:
        """è·å–åµŒå¥—å­—å…¸çš„å€¼ï¼Œæ”¯æŒç‚¹å·è·¯å¾„å¦‚ 'user.nickname'"""
        keys = path.split(".")
        value = data
        for key in keys:
            if isinstance(value, dict):
                value = value.get(key)
            else:
                return None
        return value
    
    def _extract_field(self, data: Dict, field_name: str) -> Any:
        """ä»æ•°æ®ä¸­æå–å­—æ®µï¼Œå°è¯•å¤šä¸ªå¯èƒ½çš„é”®å"""
        paths = self.field_mapping.get(field_name, [field_name])
        for path in paths:
            value = self._get_nested_value(data, path)
            if value is not None:
                return value
        return None
    
    def parse_list_result(self, result: str) -> List[SNSContent]:
        """è§£æåˆ—è¡¨ç»“æœï¼ˆé€šç”¨å®ç°ï¼‰"""
        contents = []
        
        if not result or not result.strip():
            return contents
        
        try:
            data = json.loads(result)
            
            # æ”¯æŒå¤šç§è¿”å›æ ¼å¼
            if isinstance(data, list):
                items = data
            elif isinstance(data, dict):
                # å°è¯•å¤šç§å¯èƒ½çš„åˆ—è¡¨å­—æ®µ
                for key in ["items", "feeds", "notes", "data", "list", "results"]:
                    if key in data and isinstance(data[key], list):
                        items = data[key]
                        break
                else:
                    items = [data]  # å•æ¡æ•°æ®
            else:
                return contents
            
            for item in items:
                if not isinstance(item, dict):
                    continue
                
                content = self._parse_item(item)
                if content and content.feed_id:
                    contents.append(content)
                    
        except json.JSONDecodeError:
            logger.debug(f"éJSONæ ¼å¼ç»“æœï¼Œé•¿åº¦={len(result)}")
        except Exception as e:
            logger.warning(f"è§£æåˆ—è¡¨ç»“æœå¤±è´¥: {e}")
        
        return contents
    
    def _parse_item(self, item: Dict) -> Optional[SNSContent]:
        """è§£æå•ä¸ªå†…å®¹é¡¹ï¼ˆå¯è¢«å­ç±»è¦†ç›–ï¼‰"""
        feed_id = str(self._extract_field(item, "feed_id") or "")
        if not feed_id:
            return None
        
        # æå–ç‚¹èµæ•°
        like_count = self._extract_field(item, "like_count") or 0
        if isinstance(like_count, str):
            like_count = self._parse_count(like_count)
        
        # æå–è¯„è®ºæ•°
        comment_count = self._extract_field(item, "comment_count") or 0
        if isinstance(comment_count, str):
            comment_count = self._parse_count(comment_count)
        
        # æå–å›¾ç‰‡
        images = []
        img_data = self._extract_field(item, "images")
        if img_data:
            images = self._extract_images(img_data)
        
        return SNSContent(
            feed_id=feed_id,
            platform=self.platform_name,
            title=str(self._extract_field(item, "title") or ""),
            content=str(self._extract_field(item, "content") or ""),
            author=str(self._extract_field(item, "author") or ""),
            like_count=int(like_count),
            comment_count=int(comment_count),
            image_urls=images,
            url=str(self._extract_field(item, "url") or ""),
            extra=item,  # ä¿ç•™åŸå§‹æ•°æ®
        )
    
    def _parse_count(self, count_str: str) -> int:
        """è§£ææ•°é‡å­—ç¬¦ä¸²ï¼ˆå¤„ç† '1.5ä¸‡' ç­‰æ ¼å¼ï¼‰"""
        try:
            count_str = count_str.replace(",", "").strip()
            if "ä¸‡" in count_str:
                return int(float(count_str.replace("ä¸‡", "")) * 10000)
            if "k" in count_str.lower():
                return int(float(count_str.lower().replace("k", "")) * 1000)
            return int(float(count_str))
        except (ValueError, AttributeError):
            return 0
    
    def _extract_images(self, img_data: Any) -> List[str]:
        """æå–å›¾ç‰‡ URL åˆ—è¡¨"""
        images = []
        
        if isinstance(img_data, str):
            images.append(img_data)
        elif isinstance(img_data, list):
            for img in img_data:
                if isinstance(img, str):
                    images.append(img)
                elif isinstance(img, dict):
                    # å°è¯•å¤šç§ URL å­—æ®µ
                    for key in ["urlDefault", "url", "src", "originUrl", "url_default"]:
                        if img.get(key):
                            images.append(img[key])
                            break
        elif isinstance(img_data, dict):
            for key in ["urlDefault", "url", "src"]:
                if img_data.get(key):
                    images.append(img_data[key])
                    break
        
        return images
    
    def parse_detail_result(self, result: str, content: SNSContent) -> SNSContent:
        """è§£æè¯¦æƒ…ç»“æœï¼Œæ›´æ–° content"""
        try:
            data = json.loads(result)
            
            # å°è¯•æ‰¾åˆ°ä¸»è¦æ•°æ®
            detail = None
            if isinstance(data, dict):
                for key in ["data", "note", "detail", "item"]:
                    if key in data:
                        detail = data[key]
                        if isinstance(detail, dict) and "note" in detail:
                            detail = detail["note"]
                        break
                if not detail:
                    detail = data
            
            if detail:
                # æ›´æ–°æ­£æ–‡
                new_content = self._extract_field(detail, "content")
                if new_content:
                    content.content = str(new_content)
                
                # æ›´æ–°å›¾ç‰‡
                img_data = self._extract_field(detail, "images")
                if img_data:
                    content.image_urls = self._extract_images(img_data)
                
                # æ›´æ–° extra
                content.extra.update(detail)
                
        except Exception as e:
            logger.debug(f"è§£æè¯¦æƒ…å¤±è´¥: {e}")
        
        return content
    
    def get_content_url(self, content: SNSContent) -> str:
        """è·å–å†…å®¹çš„åŸå§‹é“¾æ¥"""
        if content.url:
            return content.url
        return ""


class XiaohongshuAdapter(PlatformAdapter):
    """å°çº¢ä¹¦å¹³å°é€‚é…å™¨"""
    
    platform_name = "xiaohongshu"
    
    field_mapping = {
        "feed_id": ["id", "note_id"],
        "title": ["noteCard.displayTitle", "displayTitle", "title"],
        "content": ["noteCard.desc", "desc", "content"],
        "author": ["noteCard.user.nickname", "user.nickname", "nickname"],
        "like_count": ["noteCard.interactInfo.likedCount", "interactInfo.likedCount", "likedCount"],
        "comment_count": ["noteCard.interactInfo.commentCount", "interactInfo.commentCount", "commentCount"],
        "images": ["noteCard.cover", "cover", "imageList", "images"],
        "url": [],
    }
    
    def _parse_item(self, item: Dict) -> Optional[SNSContent]:
        """å°çº¢ä¹¦ç‰¹å®šè§£æ"""
        # å°çº¢ä¹¦çš„æ•°æ®å¯èƒ½åœ¨ noteCard ä¸­
        note_card = item.get("noteCard", {})
        if note_card:
            # åˆå¹¶ noteCard æ•°æ®åˆ° item
            merged = {**item, **note_card}
            merged["noteCard"] = note_card  # ä¿ç•™åŸå§‹ç»“æ„
        else:
            merged = item
        
        content = super()._parse_item(merged)
        if content:
            # ä¿å­˜ xsec_token ç”¨äºè·å–è¯¦æƒ…
            content.extra["xsec_token"] = item.get("xsecToken", "")
        return content
    
    def get_content_url(self, content: SNSContent) -> str:
        return f"https://xiaohongshu.com/explore/{content.feed_id}"


# å¹³å°é€‚é…å™¨æ³¨å†Œè¡¨
PLATFORM_ADAPTERS: Dict[str, Type[PlatformAdapter]] = {
    "xiaohongshu": XiaohongshuAdapter,
    "generic": PlatformAdapter,
}

def get_platform_adapter(platform: str, config: Dict[str, Any]) -> PlatformAdapter:
    """è·å–å¹³å°é€‚é…å™¨"""
    adapter_class = PLATFORM_ADAPTERS.get(platform, PlatformAdapter)
    return adapter_class(config)


# ============================================================================
# æ ¸å¿ƒåŠŸèƒ½
# ============================================================================

class SNSCollector:
    """SNSå†…å®¹é‡‡é›†å™¨ - æ”¯æŒå¤šå¹³å°"""
    
    # å¹¶å‘æ§åˆ¶
    MAX_CONCURRENT_DETAILS = 3  # æœ€å¤§å¹¶å‘è·å–è¯¦æƒ…æ•°
    
    def __init__(self, config: Dict[str, Any]):
        self.config = _normalize_config(config)
        self.platform_cfg = _normalize_config(self.config.get("platform", {}))
        self.filter_cfg = _normalize_config(self.config.get("filter", {}))
        self.memory_cfg = _normalize_config(self.config.get("memory", {}))
        self.processing_cfg = _normalize_config(self.config.get("processing", {}))
        self.debug = bool(_normalize_config(self.config.get("debug", {})).get("enabled", False))
        self._personality_cache: Optional[Dict[str, str]] = None
        self._semaphore_details = asyncio.Semaphore(self.MAX_CONCURRENT_DETAILS)
        self._adapters: Dict[str, PlatformAdapter] = {}
    
    def _get_adapter(self, platform: str) -> PlatformAdapter:
        """è·å–æˆ–åˆ›å»ºå¹³å°é€‚é…å™¨"""
        if platform not in self._adapters:
            platform_config = self.platform_cfg.get(platform, {})
            self._adapters[platform] = get_platform_adapter(platform, platform_config)
        return self._adapters[platform]
    
    @staticmethod
    def _make_cache_key(platform: str, feed_id: str) -> str:
        return f"{platform}:{feed_id}"

    @staticmethod
    def _extract_feed_id_from_key_point(key_point: Any) -> Optional[str]:
        """ä» ChatHistory.key_point ä¸­æå– feed_idï¼ˆå…¼å®¹ JSON list / çº¯æ–‡æœ¬ï¼‰"""
        if not key_point:
            return None

        if isinstance(key_point, list):
            for item in key_point:
                if isinstance(item, str) and item.startswith("feed_id:"):
                    value = item.split("feed_id:", 1)[1].strip()
                    return value or None
            return None

        if not isinstance(key_point, str):
            key_point = str(key_point)

        text = key_point.strip()
        if not text:
            return None

        if text.startswith("["):
            try:
                parsed = json.loads(text)
                if isinstance(parsed, list):
                    return SNSCollector._extract_feed_id_from_key_point(parsed)
            except Exception:
                pass

        import re
        match = re.search(r"feed_id:([A-Za-z0-9_-]+)", text)
        return match.group(1) if match else None

    async def _async_load_feed_id_cache(self) -> None:
        """å¼‚æ­¥åŠ è½½ feed_id ç¼“å­˜ï¼ˆæŒ‰å¹³å°åŠ è½½ï¼Œé¿å…å…¨è¡¨æ‰«æå¯¼è‡´ç¼“å­˜ç¼ºå¤±ï¼‰"""
        global _feed_id_cache, _feed_id_cache_loaded
        if _feed_id_cache_loaded:
            return
        
        try:
            max_records = int(self.memory_cfg.get("max_records", 1000) or 1000)
            max_records = max(max_records, 0)

            platforms: List[str] = []
            for platform, cfg in (self.platform_cfg or {}).items():
                if isinstance(cfg, dict) and cfg.get("enabled", True):
                    platforms.append(platform)
            if not platforms:
                platforms = ["xiaohongshu"]

            for platform in platforms:
                try:
                    records = await database_api.db_get(
                        ChatHistory,
                        filters={"chat_id": f"sns_{platform}"},
                        order_by="-start_time",
                        limit=max_records + 300,
                    )
                except Exception as e:
                    logger.debug(f"[SNS] åŠ è½½ feed_id ç¼“å­˜å¤±è´¥ platform={platform}: {e}")
                    continue

                for r in (records or []):
                    feed_id = SNSCollector._extract_feed_id_from_key_point(r.get("key_point", ""))
                    if feed_id:
                        _feed_id_cache.add(SNSCollector._make_cache_key(platform, feed_id))
            
            logger.info(f"[SNS] åŠ è½½ feed_id ç¼“å­˜: {len(_feed_id_cache)} æ¡")
            _feed_id_cache_loaded = True
        except Exception as e:
            logger.warning(f"å¼‚æ­¥åŠ è½½ feed_id ç¼“å­˜å¤±è´¥: {e}")
    
    def _get_personality(self) -> Dict[str, str]:
        """è·å– MaiBot äººæ ¼é…ç½®"""
        if self._personality_cache:
            return self._personality_cache
        
        try:
            from src.config.config import global_config
            # global_config.personality æ˜¯ä¸€ä¸ª PersonalityConfig å¯¹è±¡
            personality_cfg = global_config.personality
            bot_cfg = global_config.bot
            self._personality_cache = {
                "personality": getattr(personality_cfg, "personality", ""),
                "interest": getattr(personality_cfg, "interest", ""),
                "nickname": getattr(bot_cfg, "nickname", ""),
            }
        except Exception as e:
            logger.warning(f"è·å–äººæ ¼é…ç½®å¤±è´¥: {e}")
            self._personality_cache = {"personality": "", "interest": "", "nickname": ""}
        
        return self._personality_cache
    
    async def collect(
        self, 
        platform: str = "xiaohongshu", 
        keyword: Optional[str] = None, 
        count: int = 10,
        preview_only: bool = False,  # é¢„è§ˆæ¨¡å¼ï¼Œä¸å†™å…¥æ•°æ®åº“
        provided_contents: Optional[List[SNSContent]] = None,  # ç›´æ¥å†™å…¥æä¾›çš„å†…å®¹ï¼ˆç”¨äº preview->collect ç¡®è®¤å†™å…¥ï¼‰
    ) -> CollectResult:
        """æ‰§è¡Œé‡‡é›†ä»»åŠ¡
        
        Args:
            platform: å¹³å°åç§°
            keyword: æœç´¢å…³é”®è¯
            count: é‡‡é›†æ•°é‡
            preview_only: é¢„è§ˆæ¨¡å¼ï¼Œåªè¿”å›ç»“æœä¸å†™å…¥
            provided_contents: å·²å®Œæˆç­›é€‰/è¯¦æƒ…çš„å†…å®¹åˆ—è¡¨ï¼ˆè·³è¿‡é‡‡é›†æµç¨‹ï¼Œç›´æ¥è¿›å…¥å†™å…¥é˜¶æ®µï¼‰
        """
        global _collector_stats
        
        result = CollectResult(success=False)

        platform = (platform or "").strip() or "xiaohongshu"
        keyword = keyword.strip() if isinstance(keyword, str) else keyword
        if keyword == "":
            keyword = None

        if provided_contents is not None:
            contents = [c for c in (provided_contents or []) if isinstance(c, SNSContent)]
            result.fetched = len(contents)
            if not contents:
                result.success = True
                return result
        else:
            count = max(int(count or 0), 0)
            if count == 0:
                result.errors.append("é‡‡é›†æ•°é‡å¿…é¡»å¤§äº 0")
                return result

        platform_config = self.platform_cfg.get(platform, {})
        if platform_config and not platform_config.get("enabled", True):
            result.errors.append(f"å¹³å°æœªå¯ç”¨: {platform}")
            return result
        
        # æ£€æŸ¥æ˜¯å¦æ­£åœ¨è¿è¡Œ
        if _collector_stats["is_running"]:
            result.errors.append("é‡‡é›†ä»»åŠ¡æ­£åœ¨è¿è¡Œä¸­")
            return result
        
        _collector_stats["is_running"] = True
        
        if self.debug:
            logger.info("=" * 60)
            logger.info(f"[SNS] ğŸš€ å¼€å§‹é‡‡é›†æµç¨‹")
            logger.info(f"[SNS]    å¹³å°: {platform}")
            logger.info(f"[SNS]    å…³é”®è¯: {keyword or '(æ¨èæµ)'}")
            logger.info(f"[SNS]    æ•°é‡: {count}")
            logger.info(f"[SNS]    é¢„è§ˆæ¨¡å¼: {preview_only}")
            logger.info("=" * 60)
        
        try:
            # åŠ è½½ feed_id ç¼“å­˜
            await self._async_load_feed_id_cache()
            if provided_contents is None:
                # 1. è·å–å†…å®¹
                if self.debug:
                    logger.info("[SNS] ğŸ“¥ é˜¶æ®µ1: è·å–ä¿¡æ¯æµ...")

                contents = await self._fetch_contents(platform, keyword, count)
                result.fetched = len(contents)

                if self.debug:
                    logger.info(f"[SNS] âœ“ è·å–åˆ° {len(contents)} æ¡å†…å®¹")
                    for i, c in enumerate(contents):
                        logger.info(f"[SNS]    [{i+1}] {c.title[:50]}{'...' if len(c.title) > 50 else ''}")
                        logger.info(f"[SNS]        ğŸ‘ {c.like_count} | ğŸ’¬ {c.comment_count} | ğŸ“ {len(c.content)}å­— | @{c.author}")

                if not contents:
                    if self.debug:
                        logger.info("[SNS] âš ï¸ æœªè·å–åˆ°å†…å®¹ï¼Œç»“æŸ")
                    result.success = True
                    return result

                # 2. åŸºç¡€è¿‡æ»¤ï¼ˆç‚¹èµæ•°ã€é»‘ç™½åå•ï¼‰
                if self.debug:
                    logger.info("-" * 60)
                    logger.info("[SNS] ğŸ” é˜¶æ®µ2: åŸºç¡€è¿‡æ»¤ï¼ˆç‚¹èµæ•°/é»‘ç™½åå•ï¼‰...")
                    logger.info(f"[SNS]    æœ€å°ç‚¹èµæ•°: {self.filter_cfg.get('min_like_count', 100)}")

                filtered = self._filter_contents(contents)
                result.filtered = result.fetched - len(filtered)

                if self.debug:
                    logger.info(f"[SNS] âœ“ åŸºç¡€è¿‡æ»¤: {len(contents)} â†’ {len(filtered)} æ¡ï¼ˆè¿‡æ»¤ {result.filtered} æ¡ï¼‰")

                # 3. äººæ ¼å…´è¶£åŒ¹é…ï¼ˆLLM åˆ¤æ–­æ˜¯å¦ç¬¦åˆ MaiBot å…´è¶£ï¼‰
                if self.debug:
                    logger.info("-" * 60)
                    logger.info("[SNS] ğŸ§  é˜¶æ®µ3: äººæ ¼å…´è¶£åŒ¹é…...")
                    personality = self._get_personality()
                    logger.info(f"[SNS]    å…´è¶£é…ç½®: {personality.get('interest', '(æœªé…ç½®)')[:80]}...")

                before_match = len(filtered)
                filtered = await self._match_personality_interest(filtered)
                result.filtered += before_match - len(filtered)

                if self.debug:
                    logger.info(f"[SNS] âœ“ äººæ ¼åŒ¹é…: {before_match} â†’ {len(filtered)} æ¡")
                    if filtered:
                        logger.info("[SNS]    æ„Ÿå…´è¶£çš„å†…å®¹:")
                        for c in filtered:
                            logger.info(f"[SNS]      âœ“ {c.title[:40]}...")

                if not filtered:
                    if self.debug:
                        logger.info("[SNS] âš ï¸ æ²¡æœ‰ç¬¦åˆå…´è¶£çš„å†…å®¹ï¼Œç»“æŸ")
                    result.success = True
                    return result

                # 4. è·å–è¯¦æƒ…ï¼ˆåªå¯¹æ„Ÿå…´è¶£çš„å†…å®¹è·å–å®Œæ•´æ­£æ–‡ï¼‰
                fetch_detail = platform_config.get("fetch_detail", True)
                if fetch_detail:
                    if self.debug:
                        logger.info("-" * 60)
                        logger.info("[SNS] ğŸ“„ é˜¶æ®µ4: è·å–è¯¦æƒ…ï¼ˆæ­£æ–‡+å›¾ç‰‡ï¼‰...")
                    filtered = await self._fetch_details(filtered, platform)
            else:
                filtered = contents

            # 5. å†™å…¥è®°å¿†ï¼ˆæˆ–é¢„è§ˆï¼‰
            if self.debug:
                logger.info("-" * 60)
                if preview_only:
                    logger.info("[SNS] ğŸ‘ï¸ é˜¶æ®µ5: é¢„è§ˆæ¨¡å¼ï¼ˆä¸å†™å…¥ï¼‰...")
                else:
                    logger.info("[SNS] ğŸ’¾ é˜¶æ®µ5: å†™å…¥è®°å¿†...")
            
            # å­˜å‚¨é¢„è§ˆå†…å®¹
            result.preview_contents = []  # type: ignore
            
            for content in filtered:
                try:
                    # ä½¿ç”¨ç¼“å­˜æ£€æŸ¥é‡å¤
                    is_dup = self._check_duplicate_cached(content)
                    if is_dup:
                        if self.debug:
                            logger.info(f"[SNS]    â­ï¸ è·³è¿‡é‡å¤: {content.title[:30]}...")
                        result.duplicate += 1
                        continue
                    
                    if preview_only:
                        # é¢„è§ˆæ¨¡å¼ï¼šåªæ”¶é›†å†…å®¹ï¼Œä¸å†™å…¥
                        result.preview_contents.append({  # type: ignore
                            "feed_id": content.feed_id,
                            "title": content.title,
                            "content": content.content[:200],
                            "author": content.author,
                            "like_count": content.like_count,
                            "image_count": len(content.image_urls),
                        })
                        result.preview_items.append(content)
                        result.written += 1
                    else:
                        await self._write_to_memory(content, platform)
                        result.written += 1
                        # æ·»åŠ åˆ°ç¼“å­˜
                        _feed_id_cache.add(self._make_cache_key(platform, content.feed_id))
                        # è®°å½•æœ€è¿‘å†™å…¥çš„è®°å¿†
                        _collector_stats["recent_memories"].append({
                            "title": content.title[:50],
                            "author": content.author,
                            "time": time.time(),
                        })
                        # åªä¿ç•™æœ€è¿‘ 20 æ¡
                        _collector_stats["recent_memories"] = _collector_stats["recent_memories"][-20:]
                    
                    if self.debug:
                        logger.info(f"[SNS]    âœ… {'é¢„è§ˆ' if preview_only else 'å†™å…¥'}æˆåŠŸ: {content.title[:30]}...")
                        logger.info(f"[SNS]       æ­£æ–‡: {content.content[:80]}{'...' if len(content.content) > 80 else ''}")
                except Exception as e:
                    logger.error(f"[SNS]    âŒ å†™å…¥å¤±è´¥: {e}")
                    result.errors.append(f"å†™å…¥å¤±è´¥: {e}")
            
            result.success = True

            # è‡ªåŠ¨æ¸…ç†ï¼ˆä»…åœ¨å†™å…¥æ¨¡å¼æ‰§è¡Œï¼‰
            if not preview_only:
                auto_days = int(self.memory_cfg.get("auto_cleanup_days", 0) or 0)
                max_records = int(self.memory_cfg.get("max_records", 0) or 0)
                if auto_days > 0 or max_records > 0:
                    await self.cleanup(
                        days=auto_days if auto_days > 0 else 36500,
                        max_records=max_records if max_records > 0 else 1000,
                    )
            
            # æ›´æ–°ç»Ÿè®¡
            _collector_stats["last_collect_time"] = time.time()
            _collector_stats["total_collected"] += result.fetched
            _collector_stats["total_written"] += result.written
            _collector_stats["total_filtered"] += result.filtered
            _collector_stats["total_duplicate"] += result.duplicate
            _collector_stats["last_result"] = result.summary()
            
            if self.debug:
                logger.info("=" * 60)
                logger.info(f"[SNS] ğŸ‰ é‡‡é›†å®Œæˆ!")
                logger.info(f"[SNS]    è·å–: {result.fetched} | è¿‡æ»¤: {result.filtered} | é‡å¤: {result.duplicate} | å†™å…¥: {result.written}")
                logger.info("=" * 60)
            
        except Exception as e:
            logger.error(f"é‡‡é›†å¤±è´¥: {e}")
            result.errors.append(str(e))
        finally:
            _collector_stats["is_running"] = False
        
        return result
    
    def _check_duplicate_cached(self, content: SNSContent) -> bool:
        """ä½¿ç”¨ç¼“å­˜æ£€æŸ¥æ˜¯å¦é‡å¤ï¼ˆå¿«é€Ÿï¼‰"""
        if not content.feed_id:
            return False
        return self._make_cache_key(content.platform, content.feed_id) in _feed_id_cache
    
    async def _fetch_contents(self, platform: str, keyword: Optional[str], count: int) -> List[SNSContent]:
        """é€šè¿‡MCPå·¥å…·è·å–å†…å®¹ï¼ˆä½¿ç”¨å¹³å°é€‚é…å™¨ï¼‰"""
        contents = []
        
        # è·å–å¹³å°é€‚é…å™¨
        adapter = self._get_adapter(platform)
        
        # è·å–MCPå·¥å…·åå‰ç¼€å’Œå·¥å…·å
        platform_config = self.platform_cfg.get(platform, {})
        mcp_prefix = platform_config.get("mcp_server_name", platform)
        
        # è·å–å·¥å…·åï¼ˆæ”¯æŒè‡ªå®šä¹‰ï¼‰
        tools_config = platform_config.get("tools", {})
        if keyword:
            tool_suffix = tools_config.get("search", adapter.default_tools.get("search", "search_feeds"))
        else:
            tool_suffix = tools_config.get("list", adapter.default_tools.get("list", "list_feeds"))
        
        tool_name = f"{mcp_prefix}_{tool_suffix}"
        
        if self.debug:
            logger.info(f"[SNS Debug] è°ƒç”¨å·¥å…·: {tool_name}")
        
        tool = tool_api.get_tool_instance(tool_name)
        if not tool:
            logger.warning(f"MCPå·¥å…· {tool_name} ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥MCPæ¡¥æ¥æ’ä»¶é…ç½®")
            return contents
        
        try:
            if keyword:
                result = await tool.direct_execute(keyword=keyword)
            else:
                result = await tool.direct_execute()
        except Exception as e:
            logger.error(f"è°ƒç”¨MCPå·¥å…· {tool_name} å¤±è´¥: {e}")
            return contents
        
        # è§£æç»“æœ
        content_str = result.get("content", "") if isinstance(result, dict) else str(result)
        
        if self.debug:
            # æ‰“å°åŸå§‹è¿”å›å†…å®¹ï¼ˆæˆªå–å‰2000å­—ç¬¦ï¼‰
            logger.info(f"[SNS Debug] MCPåŸå§‹è¿”å› (å‰2000å­—ç¬¦):\n{content_str[:2000]}")
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯é”™è¯¯å“åº”
        if content_str.startswith("âŒ") or content_str.startswith("âš ï¸") or content_str.startswith("â›”"):
            logger.warning(f"MCPå·¥å…·è¿”å›é”™è¯¯: {content_str[:100]}")
            return contents
        
        # ä½¿ç”¨é€‚é…å™¨è§£æç»“æœ
        contents = adapter.parse_list_result(content_str)
        
        # è®¾ç½®å¹³å°å
        for c in contents:
            c.platform = platform
        
        return contents[:count]
    
    async def _fetch_details(self, contents: List[SNSContent], platform: str) -> List[SNSContent]:
        """è·å–å†…å®¹è¯¦æƒ…ï¼ˆè¡¥å……æ­£æ–‡ï¼‰- å¹¶å‘ç‰ˆæœ¬ï¼Œä½¿ç”¨é€‚é…å™¨"""
        adapter = self._get_adapter(platform)
        platform_config = self.platform_cfg.get(platform, {})
        mcp_prefix = platform_config.get("mcp_server_name", platform)
        
        # è·å–è¯¦æƒ…å·¥å…·å
        tools_config = platform_config.get("tools", {})
        tool_suffix = tools_config.get("detail", adapter.default_tools.get("detail", "get_feed_detail"))
        tool_name = f"{mcp_prefix}_{tool_suffix}"
        
        tool = tool_api.get_tool_instance(tool_name)
        if not tool:
            if self.debug:
                logger.info(f"[SNS]    âš ï¸ è¯¦æƒ…å·¥å…· {tool_name} ä¸å­˜åœ¨ï¼Œè·³è¿‡")
            return contents
        
        if self.debug:
            logger.info(f"[SNS]    ä½¿ç”¨å·¥å…·: {tool_name}")
            logger.info(f"[SNS]    å¹¶å‘æ•°: {self.MAX_CONCURRENT_DETAILS}")
        
        async def fetch_single_detail(idx: int, content: SNSContent) -> SNSContent:
            """è·å–å•ä¸ªå†…å®¹çš„è¯¦æƒ…"""
            async with self._semaphore_details:
                try:
                    if self.debug:
                        logger.info(f"[SNS]    [{idx+1}/{len(contents)}] è·å–: {content.title[:30]}...")
                    
                    # æ„å»ºå‚æ•°ï¼ˆä» extra ä¸­è·å–å¹³å°ç‰¹å®šå‚æ•°ï¼‰
                    params = {"feed_id": content.feed_id}
                    if content.extra.get("xsec_token"):
                        params["xsec_token"] = content.extra["xsec_token"]
                    
                    result = await tool.direct_execute(**params)
                    
                    content_str = result.get("content", "") if isinstance(result, dict) else str(result)
                    
                    # ä½¿ç”¨é€‚é…å™¨è§£æè¯¦æƒ…
                    old_len = len(content.content)
                    content = adapter.parse_detail_result(content_str, content)
                    
                    if self.debug:
                        logger.info(f"[SNS]        âœ“ æ­£æ–‡: {old_len} â†’ {len(content.content)} å­—")
                        logger.info(f"[SNS]        âœ“ å›¾ç‰‡: {len(content.image_urls)} å¼ ")
                    
                    return content
                    
                except Exception as e:
                    if self.debug:
                        logger.warning(f"[SNS]        âŒ è·å–å¤±è´¥: {e}")
                    return content  # å³ä½¿å¤±è´¥ä¹Ÿä¿ç•™åŸå†…å®¹
        
        # å¹¶å‘è·å–æ‰€æœ‰è¯¦æƒ…
        tasks = [fetch_single_detail(i, c) for i, c in enumerate(contents)]
        updated = await asyncio.gather(*tasks)
        
        return list(updated)
    
    def _filter_contents(self, contents: List[SNSContent]) -> List[SNSContent]:
        """è¿‡æ»¤å†…å®¹"""
        min_likes = self.filter_cfg.get("min_like_count", 100)
        blacklist = self.filter_cfg.get("keyword_blacklist", [])
        whitelist = self.filter_cfg.get("keyword_whitelist", [])
        
        if self.debug:
            logger.info(f"[SNS Debug] è¿‡æ»¤é…ç½®: min_likes={min_likes}, whitelist={whitelist}, blacklist={blacklist}")
        
        filtered = []
        for c in contents:
            text = f"{c.title} {c.content}"
            
            if self.debug:
                logger.info(f"[SNS Debug] æ£€æŸ¥å†…å®¹: title={c.title[:30]}..., likes={c.like_count}")
            
            # ç™½åå•ä¼˜å…ˆä¿ç•™
            if whitelist and any(kw in text for kw in whitelist):
                if self.debug:
                    logger.info(f"[SNS Debug] âœ“ ç™½åå•å‘½ä¸­ï¼Œä¿ç•™")
                filtered.append(c)
                continue
            
            # ç‚¹èµæ•°è¿‡æ»¤
            if c.like_count < min_likes:
                if self.debug:
                    logger.info(f"[SNS Debug] âœ— ç‚¹èµæ•°ä¸è¶³: {c.like_count} < {min_likes}")
                continue
            
            # é»‘åå•è¿‡æ»¤
            if any(kw in text for kw in blacklist):
                if self.debug:
                    logger.info(f"[SNS Debug] âœ— é»‘åå•å‘½ä¸­")
                continue
            
            if self.debug:
                logger.info(f"[SNS Debug] âœ“ é€šè¿‡è¿‡æ»¤")
            filtered.append(c)
        
        return filtered
    
    async def _match_personality_interest(self, contents: List[SNSContent]) -> List[SNSContent]:
        """ä½¿ç”¨ LLM åˆ¤æ–­å†…å®¹æ˜¯å¦ç¬¦åˆ MaiBot äººæ ¼å…´è¶£"""
        if not contents:
            return []
        
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨äººæ ¼åŒ¹é…
        if not self.processing_cfg.get("enable_personality_match", False):
            if self.debug:
                logger.info("[SNS Debug] äººæ ¼åŒ¹é…æœªå¯ç”¨ï¼Œè·³è¿‡")
            return contents
        
        personality = self._get_personality()
        interest = personality.get("interest", "")
        
        if not interest:
            if self.debug:
                logger.info("[SNS Debug] æœªé…ç½®å…´è¶£ï¼Œè·³è¿‡äººæ ¼åŒ¹é…")
            return contents
        
        if self.debug:
            logger.info(f"[SNS Debug] å¼€å§‹äººæ ¼å…´è¶£åŒ¹é…ï¼Œå…´è¶£: {interest[:50]}...")
        
        # æ„å»ºå†…å®¹åˆ—è¡¨ä¾› LLM åˆ¤æ–­
        content_list = []
        for i, c in enumerate(contents):
            content_list.append(f"{i+1}. ã€{c.title}ã€‘{c.content[:100] if c.content else ''}")
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªå†…å®¹ç­›é€‰åŠ©æ‰‹ã€‚æ ¹æ®ä»¥ä¸‹äººæ ¼å…´è¶£æè¿°ï¼Œåˆ¤æ–­å“ªäº›å†…å®¹å€¼å¾—æ·±å…¥äº†è§£ã€‚

äººæ ¼å…´è¶£ï¼š{interest}

å¾…ç­›é€‰å†…å®¹ï¼š
{chr(10).join(content_list)}

è¯·è¿”å›ä½ è®¤ä¸ºç¬¦åˆè¯¥äººæ ¼å…´è¶£çš„å†…å®¹ç¼–å·ï¼Œç”¨é€—å·åˆ†éš”ã€‚
åªè¿”å›ç¼–å·ï¼Œä¾‹å¦‚ï¼š1,3,5
å¦‚æœéƒ½ä¸ç¬¦åˆï¼Œè¿”å›ï¼šæ— """

        try:
            models = llm_api.get_available_models()
            model_cfg = models.get("utils") or models.get("replyer")
            
            if not model_cfg:
                return contents
            
            success, response, _, _ = await llm_api.generate_with_model(
                prompt=prompt,
                model_config=model_cfg,
                request_type="sns_personality_match",
            )
            
            if not success or not response:
                return contents
            
            response = response.strip()
            if self.debug:
                logger.info(f"[SNS Debug] LLM å…´è¶£åŒ¹é…ç»“æœ: {response}")
            
            if response == "æ— " or not response:
                return []
            
            # è§£æç¼–å·
            matched_indices = set()
            for part in response.replace("ï¼Œ", ",").split(","):
                part = part.strip()
                if part.isdigit():
                    idx = int(part) - 1
                    if 0 <= idx < len(contents):
                        matched_indices.add(idx)
            
            matched = [contents[i] for i in sorted(matched_indices)]
            
            if self.debug:
                logger.info(f"[SNS Debug] äººæ ¼åŒ¹é…: {len(contents)} -> {len(matched)} æ¡")
                for c in matched:
                    logger.info(f"[SNS Debug]   âœ“ {c.title[:40]}...")
            
            return matched
            
        except Exception as e:
            logger.warning(f"äººæ ¼å…´è¶£åŒ¹é…å¤±è´¥: {e}")
            return contents
    
    async def _write_to_memory(self, content: SNSContent, platform: str) -> None:
        """å†™å…¥ChatHistory"""
        # ç”Ÿæˆæ‘˜è¦
        summary = await self._generate_summary(content)
        
        # å›¾ç‰‡è¯†å›¾ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        image_desc = ""
        enable_img_rec = self.processing_cfg.get("enable_image_recognition", False)
        if self.debug:
            logger.info(f"[SNS]    ğŸ“ å†™å…¥è®°å¿†: {content.title[:30]}...")
            logger.info(f"[SNS]       å›¾ç‰‡æ•°é‡: {len(content.image_urls)}")
            logger.info(f"[SNS]       è¯†å›¾å¼€å…³: {enable_img_rec}")
        
        if content.image_urls and enable_img_rec:
            image_desc = await self._recognize_images(content.image_urls[:3])
            if self.debug:
                logger.info(f"[SNS]       è¯†å›¾ç»“æœ: {image_desc[:80] if image_desc else '(æ— )'}")
        
        # æå–å…³é”®è¯
        keywords = await self._extract_keywords(content)
        
        # æ„å»ºè®°å½•
        chat_id = f"sns_{platform}"
        now = time.time()
        
        # ä½¿ç”¨é€‚é…å™¨è·å– URL
        adapter = self._get_adapter(platform)
        url = adapter.get_content_url(content)
        full_summary = f"[æ¥è‡ª{platform}] {summary}"
        if image_desc:
            full_summary += f"\n[å›¾ç‰‡å†…å®¹] {image_desc}"
        full_summary += f"\nä½œè€…: @{content.author}\nåŸæ–‡: {url}"
        
        data = {
            "chat_id": chat_id,
            "start_time": now,
            "end_time": now,
            "original_text": content.content[:500],
            "participants": json.dumps([content.author]),
            "theme": content.title or summary[:50],
            "keywords": json.dumps(keywords),
            "summary": full_summary,
            "key_point": json.dumps([f"feed_id:{content.feed_id}", f"likes:{content.like_count}"]),
        }
        
        try:
            await database_api.db_query(ChatHistory, query_type="create", data=data)
            logger.info(f"å†™å…¥SNSè®°å¿†: {content.title[:30]}...")
        except Exception as e:
            logger.error(f"å†™å…¥å¤±è´¥ï¼Œç¼“å­˜åˆ°æœ¬åœ°: {e}")
            self._cache_failed_write(data)
            raise
    
    async def _recognize_images(self, image_urls: List[str]) -> str:
        """è¯†å›¾ï¼ˆè°ƒç”¨MaiBotçš„ImageManagerï¼‰"""
        if self.debug:
            logger.info(f"[SNS] ğŸ–¼ï¸ å¼€å§‹è¯†å›¾ï¼Œå…± {len(image_urls)} å¼ å›¾ç‰‡")
        
        try:
            from src.chat.utils.utils_image import get_image_manager
            image_manager = get_image_manager()
            
            if self.debug:
                logger.info(f"[SNS]    âœ“ ImageManager åŠ è½½æˆåŠŸ")
            
            descriptions = []
            for i, url in enumerate(image_urls[:2]):  # æœ€å¤šè¯†åˆ«2å¼ 
                try:
                    if self.debug:
                        logger.info(f"[SNS]    [{i+1}] ä¸‹è½½å›¾ç‰‡: {url[:80]}...")
                    
                    # ä¸‹è½½å›¾ç‰‡å¹¶è½¬æ¢ä¸º base64
                    image_base64 = await self._download_image_as_base64(url)
                    if not image_base64:
                        if self.debug:
                            logger.info(f"[SNS]        âš ï¸ å›¾ç‰‡ä¸‹è½½å¤±è´¥")
                        continue
                    
                    if self.debug:
                        logger.info(f"[SNS]        âœ“ ä¸‹è½½æˆåŠŸï¼Œå¼€å§‹è¯†åˆ«...")
                    
                    desc = await asyncio.wait_for(
                        image_manager.get_image_description(image_base64),
                        timeout=self.processing_cfg.get("image_recognition_timeout", 30)
                    )
                    if desc:
                        descriptions.append(desc)
                        if self.debug:
                            logger.info(f"[SNS]        âœ“ è¯†åˆ«ç»“æœ: {desc[:100]}{'...' if len(desc) > 100 else ''}")
                    else:
                        if self.debug:
                            logger.info(f"[SNS]        âš ï¸ è¯†åˆ«è¿”å›ç©ºç»“æœ")
                except asyncio.TimeoutError:
                    logger.warning(f"[SNS]    âŒ è¯†å›¾è¶…æ—¶: {url[:50]}...")
                except Exception as e:
                    logger.warning(f"[SNS]    âŒ è¯†å›¾å¤±è´¥: {e}")
            
            result = "; ".join(descriptions) if descriptions else ""
            if self.debug:
                logger.info(f"[SNS]    è¯†å›¾å®Œæˆ: {len(descriptions)} å¼ æˆåŠŸ")
            return result
        except ImportError as e:
            if self.debug:
                logger.warning(f"[SNS]    âŒ ImageManager å¯¼å…¥å¤±è´¥: {e}")
            return ""
    
    async def _download_image_as_base64(self, url: str) -> Optional[str]:
        """ä¸‹è½½å›¾ç‰‡å¹¶è½¬æ¢ä¸º base64"""
        import base64
        try:
            import aiohttp
            
            timeout = aiohttp.ClientTimeout(total=15)
            async with aiohttp.ClientSession(timeout=timeout) as session:
                async with session.get(url) as response:
                    if response.status == 200:
                        image_bytes = await response.read()
                        return base64.b64encode(image_bytes).decode("utf-8")
                    else:
                        logger.warning(f"[SNS] å›¾ç‰‡ä¸‹è½½å¤±è´¥: HTTP {response.status}")
                        return None
        except Exception as e:
            logger.warning(f"[SNS] å›¾ç‰‡ä¸‹è½½å¼‚å¸¸: {e}")
            return None
    
    def _cache_failed_write(self, data: Dict) -> None:
        """ç¼“å­˜å†™å…¥å¤±è´¥çš„æ•°æ®"""
        try:
            _ensure_data_dir()
            cache = []
            if CACHE_FILE.exists():
                cache = json.loads(CACHE_FILE.read_text(encoding="utf-8"))
            cache.append({"data": data, "time": time.time()})
            CACHE_FILE.write_text(json.dumps(cache, ensure_ascii=False, indent=2), encoding="utf-8")
        except Exception as e:
            logger.error(f"ç¼“å­˜å¤±è´¥: {e}")
    
    async def retry_cached_writes(self) -> int:
        """é‡è¯•ç¼“å­˜çš„å†™å…¥"""
        if not CACHE_FILE.exists():
            return 0
        
        try:
            cache = json.loads(CACHE_FILE.read_text(encoding="utf-8"))
            success = 0
            remaining = []
            
            for item in cache:
                try:
                    await database_api.db_query(ChatHistory, query_type="create", data=item["data"])
                    success += 1
                except Exception:
                    remaining.append(item)
            
            if remaining:
                CACHE_FILE.write_text(json.dumps(remaining, ensure_ascii=False, indent=2), encoding="utf-8")
            else:
                CACHE_FILE.unlink()
            
            logger.info(f"é‡è¯•ç¼“å­˜å†™å…¥: æˆåŠŸ{success}æ¡, å‰©ä½™{len(remaining)}æ¡")
            return success
        except Exception as e:
            logger.error(f"é‡è¯•ç¼“å­˜å¤±è´¥: {e}")
            return 0
    
    async def _generate_summary(self, content: SNSContent) -> str:
        """ç”Ÿæˆæ‘˜è¦"""
        text = f"{content.title}\n{content.content}"
        
        threshold = int(self.processing_cfg.get("summary_threshold", 200) or 200)
        enable_summary = bool(self.processing_cfg.get("enable_summary", True))
        max_len = 200

        if len(text) <= threshold:
            return text

        if not enable_summary:
            return (text[:max_len] + "...") if len(text) > max_len else text
        
        # ä½¿ç”¨LLMç”Ÿæˆæ‘˜è¦
        try:
            models = llm_api.get_available_models()
            model_cfg = models.get("utils") or models.get("replyer")
            
            if model_cfg:
                prompt = (
                    "è¯·ç”¨ä¸€ä¸¤å¥è¯æ¦‚æ‹¬ä»¥ä¸‹å†…å®¹çš„æ ¸å¿ƒä¿¡æ¯ï¼Œé¿å…æ— å…³å¯’æš„ï¼Œä¸è¦è¶…è¿‡ 120 å­—ï¼š\n\n"
                    f"{text[:1500]}"
                )
                success, summary, _, _ = await llm_api.generate_with_model(
                    prompt=prompt,
                    model_config=model_cfg,
                    request_type="sns_summary",
                )
                if success and summary:
                    return summary.strip()[:200]
        except Exception as e:
            logger.warning(f"LLMæ‘˜è¦å¤±è´¥: {e}")
        
        # é™çº§ï¼šæˆªæ–­
        return (text[:max_len] + "...") if len(text) > max_len else text
    
    async def _extract_keywords(self, content: SNSContent) -> List[str]:
        """æå–å…³é”®è¯"""
        keywords = []
        
        # ä»æ ‡é¢˜æå–ï¼ˆæŒ‰ç©ºæ ¼å’Œæ ‡ç‚¹åˆ†è¯ï¼‰
        if content.title:
            import re
            words = re.split(r'[\s,ï¼Œã€‚ï¼ï¼Ÿ!?ã€]+', content.title)
            keywords.extend([w for w in words if len(w) >= 2][:3])
        
        # æ·»åŠ ä½œè€…å
        if content.author:
            keywords.append(content.author)
        
        # æ·»åŠ å¹³å°æ ‡è¯†
        keywords.append(content.platform)
        
        # å»é‡å¹¶é™åˆ¶æ•°é‡
        seen = set()
        unique = []
        for kw in keywords:
            if kw and kw not in seen:
                seen.add(kw)
                unique.append(kw)
        
        return unique[:8]
    
    async def cleanup(self, days: int = 30, max_records: Optional[int] = None) -> Tuple[int, int]:
        """æ¸…ç†æ—§è®°å¿†ï¼ˆæŒ‰å¹³å°åˆ†åˆ«æ¸…ç†ï¼Œé¿å…ä¸åŒå¹³å°äº’ç›¸æŒ¤å é…é¢ï¼‰"""
        deleted = 0
        checked = 0

        max_records = int(
            max_records
            if max_records is not None
            else (self.memory_cfg.get("max_records", 1000) or 1000)
        )
        max_records = max(max_records, 0)

        platforms: List[str] = []
        for platform, cfg in (self.platform_cfg or {}).items():
            if isinstance(cfg, dict) and cfg.get("enabled", True):
                platforms.append(platform)
        if not platforms:
            platforms = ["xiaohongshu"]

        cutoff = time.time() - int(days) * 86400

        for platform in platforms:
            chat_id = f"sns_{platform}"
            try:
                records = await database_api.db_get(
                    ChatHistory,
                    filters={"chat_id": chat_id},
                    order_by="-start_time",
                    limit=max_records + 500,
                )
            except Exception as e:
                logger.warning(f"SNSè®°å¿†æ¸…ç†æŸ¥è¯¢å¤±è´¥ platform={platform}: {e}")
                continue

            if not records:
                continue

            checked += len(records)

            ids_to_delete = set()

            # æŒ‰æ—¶é—´æ¸…ç†
            for r in records:
                if r.get("start_time", 0) < cutoff:
                    if r.get("id") is not None:
                        ids_to_delete.add(r["id"])

            # æŒ‰æ•°é‡æ¸…ç†ï¼ˆæ¯å¹³å°ä¿ç•™æœ€æ–° max_records æ¡ï¼‰
            if max_records > 0 and len(records) > max_records:
                for r in records[max_records:]:
                    if r.get("id") is not None:
                        ids_to_delete.add(r["id"])

            for record_id in ids_to_delete:
                await database_api.db_query(
                    ChatHistory,
                    query_type="delete",
                    filters={"id": record_id},
                )
                deleted += 1

        logger.info(f"SNSè®°å¿†æ¸…ç†: æ£€æŸ¥{checked}æ¡, åˆ é™¤{deleted}æ¡")
        return checked, deleted


# ============================================================================
# Dreamå·¥å…· - ä¾›åšæ¢¦æ¨¡å—è°ƒç”¨
# ============================================================================

class SNSCollectTool(BaseTool):
    """ç¤¾äº¤å¹³å°é‡‡é›†å·¥å…·"""
    
    name = "collect_sns_content"
    description = "ä»ç¤¾äº¤å¹³å°ï¼ˆå¦‚å°çº¢ä¹¦ï¼‰é‡‡é›†çƒ­é—¨å†…å®¹å¹¶å†™å…¥è®°å¿†ã€‚åœ¨åšæ¢¦æ—¶å¯ä»¥è°ƒç”¨æ­¤å·¥å…·å­¦ä¹ æ–°çŸ¥è¯†ã€‚"
    parameters = [
        ("platform", ToolParamType.STRING, "å¹³å°åç§°ï¼Œé»˜è®¤xiaohongshu", False, ["xiaohongshu"]),
        ("keyword", ToolParamType.STRING, "æœç´¢å…³é”®è¯ï¼ˆå¯é€‰ï¼‰", False, None),
        ("count", ToolParamType.INTEGER, "é‡‡é›†æ•°é‡ï¼Œé»˜è®¤5", False, None),
    ]
    available_for_llm = False  # ä¸åœ¨å›å¤æ—¶è°ƒç”¨ï¼Œåªä¾›åšæ¢¦æ¨¡å—ä½¿ç”¨
    
    async def execute(self, function_args: dict) -> dict:
        platform = function_args.get("platform", "xiaohongshu")
        keyword = function_args.get("keyword")
        count = int(function_args.get("count", 5))
        
        collector = SNSCollector(_get_config())
        result = await collector.collect(platform, keyword, count)
        
        return {"name": self.name, "content": result.summary()}
    
    async def direct_execute(self, **kwargs) -> dict:
        return await self.execute(kwargs)


class SNSCleanupTool(BaseTool):
    """ç¤¾äº¤å¹³å°è®°å¿†æ¸…ç†å·¥å…·"""
    
    name = "cleanup_sns_memory"
    description = "æ¸…ç†è¿‡æœŸçš„ç¤¾äº¤å¹³å°è®°å¿†ï¼Œä¿æŒè®°å¿†åº“æ•´æ´ã€‚"
    parameters = [
        ("days", ToolParamType.INTEGER, "æ¸…ç†å¤šå°‘å¤©å‰çš„è®°å¿†ï¼Œé»˜è®¤30", False, None),
    ]
    available_for_llm = False  # ä¸åœ¨å›å¤æ—¶è°ƒç”¨ï¼Œåªä¾›åšæ¢¦æ¨¡å—ä½¿ç”¨
    
    async def execute(self, function_args: dict) -> dict:
        days = int(function_args.get("days", 30))
        
        collector = SNSCollector(_get_config())
        checked, deleted = await collector.cleanup(days)
        
        return {"name": self.name, "content": f"æ£€æŸ¥{checked}æ¡ï¼Œåˆ é™¤{deleted}æ¡è¿‡æœŸè®°å¿†"}
    
    async def direct_execute(self, **kwargs) -> dict:
        return await self.execute(kwargs)


class SNSStatusTool(BaseTool):
    """SNS çŠ¶æ€æŸ¥è¯¢å·¥å…·ï¼ˆä¾› WebUI è°ƒç”¨ï¼‰"""
    
    name = "sns_get_status"
    description = "è·å– SNS é‡‡é›†æ’ä»¶çš„è¿è¡ŒçŠ¶æ€å’Œç»Ÿè®¡ä¿¡æ¯"
    parameters = [
        ("action", ToolParamType.STRING, "æ“ä½œç±»å‹: stats/memories/trigger", False, ["stats", "memories", "trigger"]),
        ("keyword", ToolParamType.STRING, "è§¦å‘é‡‡é›†æ—¶çš„æœç´¢å…³é”®è¯ï¼ˆå¯é€‰ï¼‰", False, None),
    ]
    available_for_llm = False
    
    async def execute(self, function_args: dict) -> dict:
        action = function_args.get("action", "stats")
        config = _get_config()
        
        if action == "stats":
            # è¿”å›ç»Ÿè®¡ä¿¡æ¯
            stats = _collector_stats.copy()
            stats["feed_id_cache_size"] = len(_feed_id_cache)
            
            # è·å–æ•°æ®åº“ä¸­çš„è®°å¿†æ•°é‡
            try:
                platform_cfg = config.get("platform", {}) if isinstance(config, dict) else {}
                platforms = [
                    p for p, cfg in platform_cfg.items()
                    if isinstance(cfg, dict) and cfg.get("enabled", True)
                ]
                if not platforms:
                    platforms = [p for p in platform_cfg.keys()] or ["xiaohongshu"]

                max_records = int(config.get("memory", {}).get("max_records", 1000) or 1000) if isinstance(config, dict) else 1000
                max_records = max(max_records, 0)

                by_platform: Dict[str, int] = {}
                total = 0
                for p in platforms:
                    records = await database_api.db_get(
                        ChatHistory,
                        filters={"chat_id": f"sns_{p}"},
                        limit=max_records + 500,
                    )
                    count = len(records or [])
                    by_platform[p] = count
                    total += count
                stats["total_memories"] = total
                stats["by_platform"] = by_platform
            except Exception:
                stats["total_memories"] = 0
                stats["by_platform"] = {}
            
            return {"name": self.name, "content": json.dumps(stats, ensure_ascii=False)}
        
        elif action == "memories":
            # è¿”å›æœ€è¿‘çš„è®°å¿†åˆ—è¡¨
            try:
                platform_cfg = config.get("platform", {}) if isinstance(config, dict) else {}
                platforms = [
                    p for p, cfg in platform_cfg.items()
                    if isinstance(cfg, dict) and cfg.get("enabled", True)
                ]
                if not platforms:
                    platforms = [p for p in platform_cfg.keys()] or ["xiaohongshu"]

                merged: List[Dict[str, Any]] = []
                for p in platforms:
                    records = await database_api.db_get(
                        ChatHistory,
                        filters={"chat_id": f"sns_{p}"},
                        order_by="-start_time",
                        limit=20,
                    )
                    for r in (records or []):
                        merged.append({
                            "id": r.get("id"),
                            "platform": p,
                            "theme": r.get("theme", ""),
                            "summary": (r.get("summary", "") or "")[:200],
                            "time": r.get("start_time", 0),
                        })

                merged.sort(key=lambda x: x.get("time", 0), reverse=True)
                return {"name": self.name, "content": json.dumps(merged[:20], ensure_ascii=False)}
            except Exception as e:
                return {"name": self.name, "content": json.dumps({"error": str(e)})}
        
        elif action == "trigger":
            # è§¦å‘é‡‡é›†
            keyword = function_args.get("keyword")
            collector = SNSCollector(_get_config())
            result = await collector.collect(keyword=keyword if keyword else None)
            return {"name": self.name, "content": result.summary()}
        
        return {"name": self.name, "content": "unknown action"}
    
    async def direct_execute(self, **kwargs) -> dict:
        return await self.execute(kwargs)


# ============================================================================
# å‘½ä»¤å¤„ç†å™¨
# ============================================================================

class SNSCommand(BaseCommand):
    """SNSå‘½ä»¤"""
    
    command_name = "sns_command"
    command_description = "ç¤¾äº¤å¹³å°é‡‡é›†å‘½ä»¤"
    command_pattern = r"^[/ï¼]sns(?:\s+(?P<action>collect|search|status|cleanup|config|dream|preview|stats))?(?:\s+(?P<arg>.+))?$"
    
    async def execute(self) -> Tuple[bool, str, bool]:
        action = self.matched_groups.get("action", "collect")
        arg = self.matched_groups.get("arg", "")
        
        config = _get_config()
        collector = SNSCollector(config)
        stream_id = getattr(getattr(self.message, "chat_stream", None), "stream_id", "") or ""
        
        if action == "collect":
            keyword = arg.strip() if isinstance(arg, str) else ""

            if keyword:
                result = await collector.collect(keyword=keyword)
                await self.send_text(f"SNSé‡‡é›†å®Œæˆ\n{result.summary()}")
                return True, "å‘½ä»¤æ‰§è¡Œå®Œæˆ", True

            # æ— å‚æ•°ï¼šä¼˜å…ˆä½œä¸º preview çš„ç¡®è®¤å†™å…¥
            state = _load_state()
            preview = (state.get("preview") or {}).get(stream_id) if stream_id else None
            preview_ttl = 15 * 60  # 15 åˆ†é’Ÿå†…å…è®¸ç¡®è®¤å†™å…¥
            if isinstance(preview, dict) and preview.get("ts") and (time.time() - float(preview["ts"])) <= preview_ttl:
                items_data = preview.get("items") or []
                items: List[SNSContent] = []
                if isinstance(items_data, list):
                    for d in items_data:
                        if isinstance(d, dict):
                            try:
                                items.append(
                                    SNSContent(
                                        feed_id=str(d.get("feed_id", "")),
                                        platform=str(d.get("platform", "xiaohongshu")),
                                        title=str(d.get("title", "")),
                                        content=str(d.get("content", "")),
                                        author=str(d.get("author", "")),
                                        like_count=int(d.get("like_count", 0) or 0),
                                        comment_count=int(d.get("comment_count", 0) or 0),
                                        image_urls=list(d.get("image_urls") or []),
                                        url=str(d.get("url", "")),
                                        extra=dict(d.get("extra") or {}),
                                    )
                                )
                            except Exception:
                                continue

                if items:
                    result = await collector.collect(
                        platform=items[0].platform or "xiaohongshu",
                        provided_contents=items,
                        count=len(items),
                        preview_only=False,
                    )
                    # ç¡®è®¤åæ¸…ç©ºé¢„è§ˆç¼“å­˜
                    try:
                        if stream_id and isinstance(state.get("preview"), dict) and stream_id in state["preview"]:
                            del state["preview"][stream_id]
                            _save_state(state)
                    except Exception:
                        pass
                    await self.send_text(f"SNSå†™å…¥ï¼ˆæ¥è‡ªé¢„è§ˆç¡®è®¤ï¼‰å®Œæˆ\n{result.summary()}")
                    return True, "å‘½ä»¤æ‰§è¡Œå®Œæˆ", True

            result = await collector.collect()
            await self.send_text(f"SNSé‡‡é›†å®Œæˆ\n{result.summary()}")
        
        elif action == "preview":
            # é¢„è§ˆæ¨¡å¼ï¼šåªè·å–å†…å®¹ï¼Œä¸å†™å…¥æ•°æ®åº“
            await self.send_text("ğŸ‘ï¸ é¢„è§ˆæ¨¡å¼ï¼šè·å–å†…å®¹ä¸­...")
            keyword = arg.strip() if isinstance(arg, str) else ""
            result = await collector.collect(keyword=keyword if keyword else None, preview_only=True)
            
            if hasattr(result, 'preview_contents') and result.preview_contents:  # type: ignore
                preview_text = f"ğŸ“‹ é¢„è§ˆç»“æœ ({len(result.preview_contents)} æ¡):\n\n"  # type: ignore
                for i, item in enumerate(result.preview_contents[:5]):  # type: ignore
                    preview_text += f"{i+1}. ã€{item['title'][:30]}ã€‘\n"
                    preview_text += f"   ğŸ‘ {item['like_count']} | @{item['author']} | ğŸ“· {item['image_count']}å¼ \n"
                    preview_text += f"   {item['content'][:50]}...\n\n"
                
                if len(result.preview_contents) > 5:  # type: ignore
                    preview_text += f"... è¿˜æœ‰ {len(result.preview_contents) - 5} æ¡\n"  # type: ignore
                preview_text += "\nä½¿ç”¨ /sns collect ç¡®è®¤å†™å…¥"
                await self.send_text(preview_text)

                # ä¿å­˜é¢„è§ˆç¼“å­˜ï¼Œä¾› /sns collect ç¡®è®¤å†™å…¥
                if stream_id and result.preview_items:
                    state = _load_state()
                    state.setdefault("preview", {})
                    state["preview"][stream_id] = {
                        "ts": time.time(),
                        "keyword": keyword,
                        "items": [asdict(c) for c in result.preview_items],
                    }
                    _save_state(state)
            else:
                await self.send_text(f"é¢„è§ˆå®Œæˆ\n{result.summary()}\nï¼ˆæ— ç¬¦åˆæ¡ä»¶çš„å†…å®¹ï¼‰")
        
        elif action == "stats":
            # æ˜¾ç¤ºé‡‡é›†ç»Ÿè®¡
            stats = _collector_stats
            last_time = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(stats["last_collect_time"])) if stats["last_collect_time"] else "ä»æœª"
            
            stats_text = (
                f"ğŸ“Š SNS é‡‡é›†ç»Ÿè®¡\n"
                f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                f"ä¸Šæ¬¡é‡‡é›†: {last_time}\n"
                f"è¿è¡ŒçŠ¶æ€: {'ğŸŸ¢ è¿è¡Œä¸­' if stats['is_running'] else 'âšª ç©ºé—²'}\n"
                f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                f"ç´¯è®¡è·å–: {stats['total_collected']} æ¡\n"
                f"ç´¯è®¡å†™å…¥: {stats['total_written']} æ¡\n"
                f"ç´¯è®¡è¿‡æ»¤: {stats['total_filtered']} æ¡\n"
                f"ç´¯è®¡é‡å¤: {stats['total_duplicate']} æ¡\n"
                f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                f"ç¼“å­˜ feed_id: {len(_feed_id_cache)} æ¡\n"
            )
            
            if stats["recent_memories"]:
                stats_text += f"\nğŸ“ æœ€è¿‘å†™å…¥:\n"
                for mem in stats["recent_memories"][-5:]:
                    mem_time = time.strftime("%H:%M", time.localtime(mem["time"]))
                    stats_text += f"  [{mem_time}] {mem['title'][:25]}...\n"
            
            await self.send_text(stats_text)
        
        elif action == "dream":
            # æ¨¡æ‹Ÿåšæ¢¦å¼é‡‡é›†ï¼šå¸¦äººæ ¼å…´è¶£åŒ¹é…çš„é‡‡é›†
            await self.send_text("ğŸŒ™ å¼€å§‹åšæ¢¦å¼é‡‡é›†ï¼ˆå¸¦äººæ ¼å…´è¶£åŒ¹é…ï¼‰...")
            
            # å¼ºåˆ¶å¼€å¯äººæ ¼åŒ¹é…ï¼ˆé¿å…ä¿®æ”¹åŸé…ç½®å¯¹è±¡ï¼‰
            import copy

            dream_config = copy.deepcopy(config)
            if "processing" not in dream_config:
                dream_config["processing"] = {}
            dream_config["processing"]["enable_personality_match"] = True
            
            dream_collector = SNSCollector(dream_config)
            result = await dream_collector.collect(count=15)  # å¤šè·å–ä¸€äº›ï¼Œè®© LLM ç­›é€‰
            
            await self.send_text(f"ğŸŒ™ åšæ¢¦é‡‡é›†å®Œæˆ\n{result.summary()}")
            
        elif action == "search":
            if not arg:
                await self.send_text("è¯·æä¾›æœç´¢å…³é”®è¯ï¼Œä¾‹å¦‚: /sns search æ—…æ¸¸æ”»ç•¥")
                return True, "ç¼ºå°‘å…³é”®è¯", True
            result = await collector.collect(keyword=arg)
            await self.send_text(f"SNSæœç´¢ã€Œ{arg}ã€å®Œæˆ\n{result.summary()}")
            
        elif action == "cleanup":
            days = int(arg) if arg.isdigit() else 30
            checked, deleted = await collector.cleanup(days)
            await self.send_text(f"SNSæ¸…ç†å®Œæˆ: æ£€æŸ¥{checked}æ¡, åˆ é™¤{deleted}æ¡")
            
        elif action == "status":
            records = await database_api.db_get(ChatHistory, limit=1000)
            sns_records = [r for r in (records or []) if str(r.get("chat_id", "")).startswith("sns_")]
            
            # æŒ‰å¹³å°ç»Ÿè®¡
            by_platform = {}
            for r in sns_records:
                p = r.get("chat_id", "").replace("sns_", "")
                by_platform[p] = by_platform.get(p, 0) + 1
            
            status = f"SNSè®°å¿†ç»Ÿè®¡: å…±{len(sns_records)}æ¡\n"
            for p, c in by_platform.items():
                status += f"  - {p}: {c}æ¡\n"
            await self.send_text(status)
            
        elif action == "config":
            cfg = config
            config_info = (
                f"SNSé…ç½®:\n"
                f"  æœ€å°ç‚¹èµæ•°: {cfg.get('filter', {}).get('min_like_count', 100)}\n"
                f"  æœ€å¤§è®°å½•æ•°: {cfg.get('memory', {}).get('max_records', 1000)}\n"
                f"  è‡ªåŠ¨æ¸…ç†: {cfg.get('memory', {}).get('auto_cleanup_days', 30)}å¤©\n"
                f"  è¯†å›¾åŠŸèƒ½: {'å¼€å¯' if cfg.get('processing', {}).get('enable_image_recognition') else 'å…³é—­'}"
            )
            await self.send_text(config_info)
            
        else:
            help_text = (
                "ğŸ“± SNS é‡‡é›†å‘½ä»¤\n"
                "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                "/sns collect     - é‡‡é›†æ¨èå†…å®¹\n"
                "/sns preview     - é¢„è§ˆå†…å®¹ï¼ˆä¸å†™å…¥ï¼‰\n"
                "/sns search <è¯> - æœç´¢ç‰¹å®šå†…å®¹\n"
                "/sns dream       - åšæ¢¦å¼é‡‡é›†\n"
                "/sns stats       - æŸ¥çœ‹é‡‡é›†ç»Ÿè®¡\n"
                "/sns status      - æŸ¥çœ‹è®°å¿†ç»Ÿè®¡\n"
                "/sns cleanup [å¤©] - æ¸…ç†æ—§è®°å¿†\n"
                "/sns config      - æŸ¥çœ‹é…ç½®"
            )
            await self.send_text(help_text)
        
        return True, "å‘½ä»¤æ‰§è¡Œå®Œæˆ", True


# ============================================================================
# å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨
# ============================================================================

class SNSScheduler:
    """å®šæ—¶é‡‡é›†è°ƒåº¦å™¨"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.running = False
        self._task: Optional[asyncio.Task] = None
        self._lock = asyncio.Lock()
    
    async def start(self) -> None:
        """å¯åŠ¨è°ƒåº¦å™¨"""
        if self.running:
            return

        interval = float(self.config.get("scheduler", {}).get("interval_minutes", 60) or 0) * 60
        if interval <= 0:
            self.running = False
            logger.info("SNSå®šæ—¶ä»»åŠ¡å·²ç¦ç”¨")
            return

        self.running = True
        
        self._task = asyncio.create_task(self._run_loop(interval))
        logger.info(f"SNSå®šæ—¶ä»»åŠ¡å¯åŠ¨ï¼Œé—´éš”{interval // 60}åˆ†é’Ÿ")
    
    async def stop(self) -> None:
        """åœæ­¢è°ƒåº¦å™¨"""
        self.running = False
        if self._task:
            self._task.cancel()
            try:
                await self._task
            except asyncio.CancelledError:
                pass
        logger.info("SNSå®šæ—¶ä»»åŠ¡å·²åœæ­¢")
    
    async def _run_loop(self, interval: float) -> None:
        """å®šæ—¶æ‰§è¡Œå¾ªç¯"""
        # é¦–æ¬¡å»¶è¿Ÿ
        first_delay = self.config.get("scheduler", {}).get("first_delay_minutes", 5) * 60
        await asyncio.sleep(first_delay)
        
        while self.running:
            async with self._lock:  # é˜²æ­¢å¹¶å‘
                try:
                    collector = SNSCollector(self.config)
                    
                    # é‡è¯•ç¼“å­˜çš„å†™å…¥
                    await collector.retry_cached_writes()
                    
                    # æ‰§è¡Œé‡‡é›†
                    tasks = self.config.get("scheduler", {}).get("tasks", [])
                    if not tasks:
                        tasks = [{"platform": "xiaohongshu"}]
                    
                    for task in tasks:
                        if not task.get("enabled", True):
                            continue
                        result = await collector.collect(
                            platform=task.get("platform", "xiaohongshu"),
                            keyword=task.get("keyword"),
                            count=task.get("count", 10),
                        )
                        logger.info(f"å®šæ—¶é‡‡é›†å®Œæˆ: {result.summary()}")
                    
                except Exception as e:
                    logger.error(f"å®šæ—¶é‡‡é›†å¤±è´¥: {e}")
            
            await asyncio.sleep(interval)


# å…¨å±€å®ä¾‹
_scheduler: Optional[SNSScheduler] = None
_plugin_instance: Optional["MaiBotSNSPlugin"] = None


def _get_config() -> Dict[str, Any]:
    """è·å–æ’ä»¶é…ç½®"""
    global _plugin_instance
    if _plugin_instance and hasattr(_plugin_instance, "config"):
        return _normalize_config(_plugin_instance.config)
    return {}


def _register_dream_tools() -> None:
    """æ³¨å†Œ SNS å·¥å…·åˆ°åšæ¢¦æ¨¡å—"""
    try:
        from src.dream.dream_agent import get_dream_tool_registry, DreamTool
        from src.llm_models.payload_content.tool_option import ToolParamType
        
        registry = get_dream_tool_registry()
        
        # åˆ›å»º SNS é‡‡é›†å·¥å…·çš„æ‰§è¡Œå‡½æ•°
        async def collect_sns_content(platform: str = "xiaohongshu", keyword: str = "", count: int = 10) -> str:
            """æ‰§è¡Œ SNS é‡‡é›†"""
            import copy

            config = copy.deepcopy(_get_config())
            if "processing" not in config:
                config["processing"] = {}
            config["processing"]["enable_personality_match"] = True
            
            collector = SNSCollector(config)
            result = await collector.collect(
                platform=platform,
                keyword=keyword if keyword else None,
                count=int(count)
            )
            return f"SNSé‡‡é›†å®Œæˆ: {result.summary()}"
        
        # æ³¨å†Œé‡‡é›†å·¥å…·
        registry.register_tool(
            DreamTool(
                name="collect_sns_content",
                description="ä»ç¤¾äº¤å¹³å°ï¼ˆå¦‚å°çº¢ä¹¦ï¼‰é‡‡é›†å†…å®¹å¹¶å†™å…¥è®°å¿†ã€‚ä¼šæ ¹æ®ä½ çš„å…´è¶£è‡ªåŠ¨ç­›é€‰å†…å®¹ï¼Œåªä¿ç•™æ„Ÿå…´è¶£çš„ä¿¡æ¯ã€‚é€‚åˆåœ¨åšæ¢¦æ—¶å­¦ä¹ æ–°çŸ¥è¯†ã€äº†è§£çƒ­é—¨è¯é¢˜ã€‚",
                parameters=[
                    ("platform", ToolParamType.STRING, "å¹³å°åç§°ï¼Œç›®å‰æ”¯æŒ xiaohongshuï¼ˆå°çº¢ä¹¦ï¼‰", False, None),
                    ("keyword", ToolParamType.STRING, "æœç´¢å…³é”®è¯ï¼ˆå¯é€‰ï¼‰ï¼Œç•™ç©ºåˆ™è·å–æ¨èå†…å®¹", False, None),
                    ("count", ToolParamType.INTEGER, "è·å–æ•°é‡ï¼Œé»˜è®¤10ï¼Œå»ºè®®5-20", False, None),
                ],
                execute_func=collect_sns_content,
            )
        )
        
        logger.info("[SNS] âœ“ å·²æ³¨å†Œ Dream å·¥å…·: collect_sns_content")
        
    except ImportError as e:
        logger.debug(f"[SNS] åšæ¢¦æ¨¡å—æœªåŠ è½½ï¼Œè·³è¿‡ Dream å·¥å…·æ³¨å†Œ: {e}")
    except Exception as e:
        logger.warning(f"[SNS] æ³¨å†Œ Dream å·¥å…·å¤±è´¥: {e}")


def _register_memory_retrieval_tools() -> None:
    """æ³¨å†Œ SNS è®°å¿†æœç´¢å·¥å…·åˆ°è®°å¿†æ£€ç´¢ç³»ç»Ÿ"""
    logger.info("[SNS] å¼€å§‹æ³¨å†Œè®°å¿†æ£€ç´¢å·¥å…·...")
    try:
        from src.memory_system.retrieval_tools import register_memory_retrieval_tool
        logger.info("[SNS] æˆåŠŸå¯¼å…¥ register_memory_retrieval_tool")
        
        async def search_sns_memory(chat_id: str, keyword: Optional[str] = None) -> str:
            """æœç´¢ SNS è®°å¿†ï¼ˆç¤¾äº¤å¹³å°é‡‡é›†çš„å†…å®¹ï¼‰"""
            if not keyword:
                return "è¯·æä¾›æœç´¢å…³é”®è¯"
            
            try:
                config = _get_config()
                platform_cfg = config.get("platform", {}) if isinstance(config, dict) else {}
                platforms = [
                    p for p, cfg in platform_cfg.items()
                    if isinstance(cfg, dict) and cfg.get("enabled", True)
                ]
                if not platforms:
                    platforms = [p for p in platform_cfg.keys()] or ["xiaohongshu"]

                # å…³é”®è¯è§£æï¼šå¤ç”¨ MaiBot çš„ç»Ÿä¸€è§„åˆ™ï¼ˆå«ç©ºæ ¼/é€—å·/æ–œæ ç­‰ï¼‰
                try:
                    from src.chat.utils.utils import parse_keywords_string

                    keywords = parse_keywords_string(keyword) or []
                except Exception:
                    keywords = []

                if not keywords:
                    keywords = [kw for kw in (keyword or "").split() if kw.strip()]
                keywords = [kw.strip() for kw in keywords if kw and kw.strip()]
                if not keywords:
                    return "è¯·æä¾›æœ‰æ•ˆçš„æœç´¢å…³é”®è¯"

                # Peewee ç›´æ¥æŸ¥è¯¢ï¼ˆé¿å…å…¨é‡æ‹‰å–åˆ°å†…å­˜ï¼‰
                chat_ids = [f"sns_{p}" for p in platforms]
                query = ChatHistory.select(
                    ChatHistory.id,
                    ChatHistory.chat_id,
                    ChatHistory.theme,
                    ChatHistory.keywords,
                    ChatHistory.summary,
                    ChatHistory.start_time,
                ).where(ChatHistory.chat_id.in_(chat_ids))

                kw_cond = None
                for kw in keywords:
                    c = (
                        (ChatHistory.theme.contains(kw))
                        | (ChatHistory.summary.contains(kw))
                        | (ChatHistory.keywords.contains(kw))
                        | (ChatHistory.original_text.contains(kw))
                    )
                    kw_cond = c if kw_cond is None else (kw_cond | c)

                if kw_cond is not None:
                    query = query.where(kw_cond)

                records = list(query.order_by(ChatHistory.start_time.desc()).limit(50))
                if not records:
                    return f"æœªæ‰¾åˆ°åŒ…å«å…³é”®è¯ã€Œ{keyword}ã€çš„ SNS è®°å¿†"

                results = []
                for r in records[:10]:
                    platform = (getattr(r, "chat_id", "") or "").replace("sns_", "")
                    results.append(
                        f"è®°å¿†IDï¼š{getattr(r, 'id', None)}\n"
                        f"æ¥æºï¼š{platform}\n"
                        f"ä¸»é¢˜ï¼š{getattr(r, 'theme', '(æ— )') or '(æ— )'}\n"
                        f"å…³é”®è¯ï¼š{getattr(r, 'keywords', '(æ— )') or '(æ— )'}"
                    )

                return f"æ‰¾åˆ° {len(records)} æ¡ SNS è®°å¿†ï¼ˆæ˜¾ç¤ºå‰{len(results)}æ¡ï¼‰ï¼š\n\n" + "\n\n---\n\n".join(results)
                
            except Exception as e:
                logger.error(f"æœç´¢ SNS è®°å¿†å¤±è´¥: {e}")
                return f"æœç´¢å¤±è´¥: {e}"
        
        async def get_sns_memory_detail(chat_id: str, memory_ids: str) -> str:
            """è·å– SNS è®°å¿†è¯¦æƒ…"""
            try:
                # è§£æ ID åˆ—è¡¨
                id_list = [int(id_str.strip()) for id_str in memory_ids.split(",") if id_str.strip().isdigit()]
                if not id_list:
                    return "è¯·æä¾›æœ‰æ•ˆçš„è®°å¿†ID"

                # åªå…è®¸è¯»å– sns_* è®°å½•ï¼Œé¿å…é€šè¿‡ ID è¯»å–é SNS è®°å¿†
                query = (
                    ChatHistory.select(
                        ChatHistory.id,
                        ChatHistory.chat_id,
                        ChatHistory.theme,
                        ChatHistory.summary,
                        ChatHistory.keywords,
                        ChatHistory.start_time,
                    )
                    .where(ChatHistory.id.in_(id_list))
                    .where(ChatHistory.chat_id.startswith("sns_"))
                )
                matched = list(query.limit(len(id_list)))
                
                if not matched:
                    return f"æœªæ‰¾åˆ°IDä¸º {id_list} çš„è®°å¿†"
                
                # æ„å»ºè¯¦æƒ…
                results = []
                for r in matched:
                    parts = [
                        f"è®°å¿†IDï¼š{getattr(r, 'id', None)}",
                        f"æ¥æºï¼š{(getattr(r, 'chat_id', '') or '').replace('sns_', '')}",
                        f"ä¸»é¢˜ï¼š{getattr(r, 'theme', '(æ— )') or '(æ— )'}",
                    ]
                    if getattr(r, "summary", None):
                        parts.append(f"æ¦‚æ‹¬ï¼š{getattr(r, 'summary')}")
                    if getattr(r, "keywords", None):
                        parts.append(f"å…³é”®è¯ï¼š{getattr(r, 'keywords')}")
                    results.append("\n".join(parts))
                
                return "\n\n" + ("=" * 50) + "\n\n" + "\n\n".join(results)
                
            except Exception as e:
                logger.error(f"è·å– SNS è®°å¿†è¯¦æƒ…å¤±è´¥: {e}")
                return f"è·å–å¤±è´¥: {e}"
        
        # æ³¨å†Œæœç´¢å·¥å…·
        register_memory_retrieval_tool(
            name="search_sns_memory",
            description="æœç´¢ä»å°çº¢ä¹¦ç­‰ç¤¾äº¤å¹³å°é‡‡é›†çš„å¤–éƒ¨çŸ¥è¯†è®°å¿†ã€‚é€‚ç”¨äºæŸ¥æ‰¾ï¼šäº§å“èµ„è®¯ï¼ˆå¦‚XREALã€æ‰‹æœºã€ç›¸æœºï¼‰ã€ç§‘æŠ€æ•°ç ã€AIå·¥å…·ã€æ¸¸æˆåŠ¨æ¼«ã€çƒ­é—¨è¯é¢˜ç­‰ã€‚å½“search_chat_historyæ‰¾ä¸åˆ°ä¿¡æ¯æ—¶ï¼Œå¯ä»¥å°è¯•æ­¤å·¥å…·æœç´¢å¤–éƒ¨æ¥æºçš„çŸ¥è¯†ã€‚",
            parameters=[
                {"name": "keyword", "type": "string", "description": "æœç´¢å…³é”®è¯ï¼ˆå¦‚ï¼šXREALã€Tanvasã€AIã€æ‰‹æœºã€æ¸¸æˆç­‰ï¼‰", "required": True},
            ],
            execute_func=search_sns_memory,
        )
        
        # æ³¨å†Œè¯¦æƒ…å·¥å…·
        register_memory_retrieval_tool(
            name="get_sns_memory_detail",
            description="è·å–ç¤¾äº¤å¹³å°è®°å¿†çš„è¯¦ç»†å†…å®¹ã€‚éœ€è¦å…ˆä½¿ç”¨ search_sns_memory è·å–è®°å¿†IDã€‚",
            parameters=[
                {"name": "memory_ids", "type": "string", "description": "è®°å¿†IDï¼Œå¯ä»¥æ˜¯å•ä¸ªIDæˆ–å¤šä¸ªIDï¼ˆé€—å·åˆ†éš”ï¼‰", "required": True},
            ],
            execute_func=get_sns_memory_detail,
        )
        
        logger.info("[SNS] âœ“ å·²æ³¨å†Œè®°å¿†æ£€ç´¢å·¥å…·: search_sns_memory, get_sns_memory_detail")
        
    except ImportError as e:
        logger.debug(f"[SNS] è®°å¿†æ£€ç´¢æ¨¡å—æœªåŠ è½½ï¼Œè·³è¿‡å·¥å…·æ³¨å†Œ: {e}")
    except Exception as e:
        logger.warning(f"[SNS] æ³¨å†Œè®°å¿†æ£€ç´¢å·¥å…·å¤±è´¥: {e}")


# ============================================================================
# äº‹ä»¶å¤„ç†å™¨
# ============================================================================

class SNSStartupHandler(BaseEventHandler):
    """æ’ä»¶å¯åŠ¨äº‹ä»¶å¤„ç†"""
    
    event_type = EventType.ON_START
    handler_name = "sns_startup_handler"
    handler_description = "SNSæ’ä»¶å¯åŠ¨å¤„ç†å™¨"
    weight = 0
    intercept_message = False
    
    async def execute(self, message: Optional[Any]) -> Tuple[bool, bool, Optional[str], None, None]:
        global _scheduler
        
        logger.info("MaiBot_SNS æ’ä»¶å¯åŠ¨")
        
        config = _get_config()
        
        # æ³¨å†Œ Dream å·¥å…·ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if config.get("dream", {}).get("enabled", True):
            _register_dream_tools()
        
        # æ³¨å†Œè®°å¿†æ£€ç´¢å·¥å…·ï¼ˆè®© MaiBot å›å¿†æ—¶èƒ½æœç´¢ SNS è®°å¿†ï¼‰
        _register_memory_retrieval_tools()
        
        # å¯åŠ¨å®šæ—¶è°ƒåº¦å™¨
        if config.get("scheduler", {}).get("enabled", False):
            _scheduler = SNSScheduler(config)
            await _scheduler.start()
        
        return (True, True, None, None, None)


class SNSShutdownHandler(BaseEventHandler):
    """æ’ä»¶åœæ­¢äº‹ä»¶å¤„ç†"""
    
    event_type = EventType.ON_STOP
    handler_name = "sns_shutdown_handler"
    handler_description = "SNSæ’ä»¶åœæ­¢å¤„ç†å™¨"
    weight = 0
    intercept_message = False
    
    async def execute(self, message: Optional[Any]) -> Tuple[bool, bool, Optional[str], None, None]:
        global _scheduler
        
        logger.info("MaiBot_SNS æ’ä»¶åœæ­¢")
        
        if _scheduler:
            await _scheduler.stop()
            _scheduler = None
        
        return (True, True, None, None, None)


# ============================================================================
# æ’ä»¶ä¸»ç±»
# ============================================================================

@register_plugin
class MaiBotSNSPlugin(BasePlugin):
    """MaiBot SNSæ’ä»¶"""
    
    plugin_name = "maibot_sns"
    enable_plugin = True
    dependencies = ["mcp_bridge_plugin"]
    python_dependencies = [
        PythonDependency(
            package_name="aiohttp",
            version="",
            optional=True,
            description="ç”¨äºä¸‹è½½å›¾ç‰‡å¹¶è½¬ä¸º base64ï¼ˆå›¾ç‰‡è¯†åˆ«åŠŸèƒ½éœ€è¦ï¼‰",
        ),
    ]
    config_file_name = "config.toml"
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        global _plugin_instance
        _plugin_instance = self
    
    # Section æè¿°ï¼ˆç”¨äº WebUI æ˜¾ç¤ºï¼‰
    config_section_descriptions = {
        "plugin": ConfigSection(
            title="æ’ä»¶è®¾ç½®",
            description="åŸºç¡€æ’ä»¶é…ç½®",
            icon="settings",
            order=0,
        ),
        "platform": ConfigSection(
            title="å¹³å°é…ç½®",
            description="é…ç½®è¦é‡‡é›†çš„ç¤¾äº¤å¹³å°",
            icon="globe",
            order=1,
        ),
        "filter": ConfigSection(
            title="å†…å®¹è¿‡æ»¤",
            description="è®¾ç½®è¿‡æ»¤è§„åˆ™ï¼Œåªä¿å­˜æœ‰ä»·å€¼çš„å†…å®¹",
            icon="filter",
            order=2,
        ),
        "processing": ConfigSection(
            title="å†…å®¹å¤„ç†",
            description="LLM æ‘˜è¦ã€å›¾ç‰‡è¯†åˆ«ç­‰å¤„ç†é€‰é¡¹",
            icon="cpu",
            order=3,
        ),
        "memory": ConfigSection(
            title="è®°å¿†å­˜å‚¨",
            description="è®°å¿†æ•°é‡å’Œæ¸…ç†è®¾ç½®",
            icon="database",
            order=4,
        ),
        "scheduler": ConfigSection(
            title="å®šæ—¶ä»»åŠ¡",
            description="è‡ªåŠ¨é‡‡é›†ä»»åŠ¡é…ç½®",
            icon="clock",
            order=5,
            collapsed=True,
        ),
        "dream": ConfigSection(
            title="åšæ¢¦é›†æˆ",
            description="åšæ¢¦æ¨¡å—é›†æˆé…ç½®",
            icon="moon",
            order=6,
            collapsed=True,
        ),
        "debug": ConfigSection(
            title="è°ƒè¯•",
            description="è°ƒè¯•æ—¥å¿—é…ç½®",
            icon="bug",
            order=99,
            collapsed=True,
        ),
    }
    
    config_schema = {
        "plugin": {
            "name": ConfigField(
                type=str, default="maibot_sns",
                description="æ’ä»¶åç§°",
                hidden=True,
            ),
            "version": ConfigField(
                type=str, default="1.0.0",
                description="ç‰ˆæœ¬",
                hidden=True,
            ),
            "enabled": ConfigField(
                type=bool, default=True,
                description="å¯ç”¨æ’ä»¶",
                label="å¯ç”¨ SNS é‡‡é›†æ’ä»¶",
                order=0,
            ),
        },
        "platform": {
            "xiaohongshu.enabled": ConfigField(
                type=bool, default=True,
                description="å¯ç”¨å°çº¢ä¹¦é‡‡é›†",
                label="å¯ç”¨å°çº¢ä¹¦",
                hint="éœ€è¦å…ˆé…ç½® MCP æ¡¥æ¥æ’ä»¶ä¸­çš„å°çº¢ä¹¦ MCP æœåŠ¡å™¨",
                order=0,
            ),
            "xiaohongshu.mcp_server_name": ConfigField(
                type=str, default="mcp_xiaohongshu",
                description="MCP æœåŠ¡å™¨åç§°",
                label="MCP æœåŠ¡å™¨å",
                hint="ä¸ MCP æ¡¥æ¥æ’ä»¶é…ç½®ä¸­çš„ name å¯¹åº”",
                placeholder="mcp_xiaohongshu",
                order=1,
            ),
            "xiaohongshu.fetch_detail": ConfigField(
                type=bool, default=True,
                description="è·å–ç¬”è®°è¯¦æƒ…",
                label="è·å–å®Œæ•´æ­£æ–‡",
                hint="å¼€å¯åä¼šè°ƒç”¨ get_feed_detail è·å–å®Œæ•´æ­£æ–‡å’Œå›¾ç‰‡",
                order=2,
            ),
        },
        "filter": {
            "min_like_count": ConfigField(
                type=int, default=100,
                description="æœ€å°ç‚¹èµæ•°",
                label="æœ€å°ç‚¹èµæ•°",
                hint="ä½äºæ­¤å€¼çš„å†…å®¹ä¼šè¢«è¿‡æ»¤ï¼Œè®¾ä¸º 0 åˆ™ä¸è¿‡æ»¤",
                min=0, max=100000, step=10,
                order=0,
            ),
            "keyword_whitelist": ConfigField(
                type=list, default=[],
                description="å…³é”®è¯ç™½åå•",
                label="ç™½åå•å…³é”®è¯",
                hint="åŒ…å«è¿™äº›å…³é”®è¯çš„å†…å®¹ä¼šä¼˜å…ˆä¿ç•™ï¼Œå³ä½¿ç‚¹èµæ•°ä¸å¤Ÿ",
                placeholder="æ•™ç¨‹, æ”»ç•¥, ç§‘æ™®",
                order=1,
            ),
            "keyword_blacklist": ConfigField(
                type=list, default=[],
                description="å…³é”®è¯é»‘åå•",
                label="é»‘åå•å…³é”®è¯",
                hint="åŒ…å«è¿™äº›å…³é”®è¯çš„å†…å®¹ä¼šè¢«ç›´æ¥è¿‡æ»¤",
                placeholder="å¹¿å‘Š, æ¨å¹¿, ä»£è´­",
                order=2,
            ),
        },
        "processing": {
            "enable_personality_match": ConfigField(
                type=bool, default=True,
                description="å¯ç”¨äººæ ¼å…´è¶£åŒ¹é…",
                label="äººæ ¼å…´è¶£åŒ¹é…",
                hint="ä½¿ç”¨ LLM åˆ¤æ–­å†…å®¹æ˜¯å¦ç¬¦åˆ MaiBot çš„å…´è¶£ï¼Œåªå­¦ä¹ æ„Ÿå…´è¶£çš„å†…å®¹",
                order=0,
            ),
            "enable_summary": ConfigField(
                type=bool, default=True,
                description="å¯ç”¨ LLM æ‘˜è¦",
                label="LLM æ‘˜è¦ç”Ÿæˆ",
                hint="å¯¹é•¿æ–‡æœ¬ç”Ÿæˆæ‘˜è¦",
                order=1,
            ),
            "summary_threshold": ConfigField(
                type=int, default=200,
                description="æ‘˜è¦è§¦å‘é•¿åº¦",
                label="æ‘˜è¦è§¦å‘é•¿åº¦ï¼ˆå­—ç¬¦ï¼‰",
                hint="è¶…è¿‡æ­¤é•¿åº¦çš„å†…å®¹æ‰ä¼šç”Ÿæˆæ‘˜è¦",
                min=50, max=2000, step=50,
                depends_on="processing.enable_summary",
                depends_value=True,
                order=2,
            ),
            "enable_image_recognition": ConfigField(
                type=bool, default=False,
                description="å¯ç”¨å›¾ç‰‡è¯†åˆ«",
                label="å›¾ç‰‡è¯†åˆ«ï¼ˆVLMï¼‰",
                hint="ä½¿ç”¨è§†è§‰æ¨¡å‹ç†è§£å›¾ç‰‡å†…å®¹ï¼Œä¼šå¢åŠ å¤„ç†æ—¶é—´å’Œ API è°ƒç”¨",
                order=3,
            ),
            "image_recognition_timeout": ConfigField(
                type=int, default=30,
                description="è¯†å›¾è¶…æ—¶æ—¶é—´",
                label="è¯†å›¾è¶…æ—¶ï¼ˆç§’ï¼‰",
                min=10, max=120, step=5,
                depends_on="processing.enable_image_recognition",
                depends_value=True,
                order=4,
            ),
        },
        "memory": {
            "max_records": ConfigField(
                type=int, default=1000,
                description="æœ€å¤§è®°å½•æ•°",
                label="æ¯å¹³å°æœ€å¤§è®°å½•æ•°",
                hint="è¶…è¿‡æ­¤æ•°é‡ä¼šè‡ªåŠ¨åˆ é™¤æœ€æ—§çš„è®°å½•",
                min=100, max=10000, step=100,
                order=0,
            ),
            "auto_cleanup_days": ConfigField(
                type=int, default=30,
                description="è‡ªåŠ¨æ¸…ç†å¤©æ•°",
                label="è®°å¿†ä¿ç•™å¤©æ•°",
                hint="è¶…è¿‡æ­¤å¤©æ•°çš„è®°å½•ä¼šè¢«è‡ªåŠ¨æ¸…ç†",
                min=7, max=365, step=1,
                order=1,
            ),
        },
        "scheduler": {
            "enabled": ConfigField(
                type=bool, default=False,
                description="å¯ç”¨å®šæ—¶é‡‡é›†",
                label="å¯ç”¨å®šæ—¶é‡‡é›†",
                hint="å»ºè®®å…ˆæ‰‹åŠ¨æµ‹è¯•æˆåŠŸåå†å¼€å¯",
                order=0,
            ),
            "interval_minutes": ConfigField(
                type=int, default=60,
                description="é‡‡é›†é—´éš”",
                label="é‡‡é›†é—´éš”ï¼ˆåˆ†é’Ÿï¼‰",
                hint="å»ºè®®ä¸è¦è®¾ç½®å¤ªçŸ­ï¼Œé¿å…é¢‘ç¹è¯·æ±‚",
                min=10, max=1440, step=10,
                depends_on="scheduler.enabled",
                depends_value=True,
                order=1,
            ),
            "first_delay_minutes": ConfigField(
                type=int, default=5,
                description="é¦–æ¬¡å»¶è¿Ÿ",
                label="é¦–æ¬¡é‡‡é›†å»¶è¿Ÿï¼ˆåˆ†é’Ÿï¼‰",
                hint="æ’ä»¶å¯åŠ¨åç­‰å¾…å¤šä¹…å¼€å§‹ç¬¬ä¸€æ¬¡é‡‡é›†",
                min=1, max=60, step=1,
                depends_on="scheduler.enabled",
                depends_value=True,
                order=2,
            ),
        },
        "dream": {
            "enabled": ConfigField(
                type=bool, default=True,
                description="å¯ç”¨åšæ¢¦æ¨¡å—é›†æˆ",
                label="åšæ¢¦æ¨¡å—é›†æˆ",
                hint="å¼€å¯ååšæ¢¦ agent å¯ä»¥è°ƒç”¨ SNS é‡‡é›†å·¥å…·ä¸»åŠ¨å­¦ä¹ ",
                order=0,
            ),
        },
        "debug": {
            "enabled": ConfigField(
                type=bool, default=False,
                description="å¯ç”¨è°ƒè¯•æ¨¡å¼",
                label="è°ƒè¯•æ—¥å¿—",
                hint="å¼€å¯åä¼šè¾“å‡ºè¯¦ç»†çš„é‡‡é›†è¿‡ç¨‹æ—¥å¿—",
                order=0,
            ),
        },
    }
    
    def get_plugin_components(self) -> List[Tuple[ComponentInfo, Type]]:
        """æ³¨å†Œç»„ä»¶"""
        return [
            (SNSCollectTool.get_tool_info(), SNSCollectTool),
            (SNSCleanupTool.get_tool_info(), SNSCleanupTool),
            (SNSStatusTool.get_tool_info(), SNSStatusTool),
            (SNSCommand.get_command_info(), SNSCommand),
            (SNSStartupHandler.get_handler_info(), SNSStartupHandler),
            (SNSShutdownHandler.get_handler_info(), SNSShutdownHandler),
        ]
