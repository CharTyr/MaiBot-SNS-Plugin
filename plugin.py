"""
MaiBot_SNS - ç¤¾äº¤å¹³å°ä¿¡æ¯é‡‡é›†ä¸è®°å¿†å†™å…¥æ’ä»¶

é€šè¿‡MCPæ¡¥æ¥è°ƒç”¨ç¤¾äº¤å¹³å°APIï¼ˆå¦‚å°çº¢ä¹¦ï¼‰ï¼Œé‡‡é›†å†…å®¹å¹¶å†™å…¥ChatHistoryè®°å¿†ç³»ç»Ÿã€‚
æ”¯æŒåšæ¢¦æ¨¡å—é›†æˆã€å®šæ—¶ä»»åŠ¡å’Œæ‰‹åŠ¨å‘½ä»¤è§¦å‘ã€‚
"""

import asyncio
import json
import time
from dataclasses import dataclass, field
from pathlib import Path
from typing import List, Tuple, Type, Optional, Dict, Any

from src.plugin_system import (
    BasePlugin,
    BaseCommand,
    BaseTool,
    ComponentInfo,
    ConfigField,
    ToolParamType,
    register_plugin,
    get_logger,
)
from src.plugin_system.base.base_events_handler import BaseEventHandler
from src.plugin_system.base.component_types import EventType
from src.plugin_system.apis import tool_api, llm_api, database_api
from src.common.database.database_model import ChatHistory

logger = get_logger("maibot_sns")

# ç¼“å­˜æ–‡ä»¶è·¯å¾„
CACHE_FILE = Path(__file__).parent / "failed_writes.json"


# ============================================================================
# æ•°æ®æ¨¡å‹
# ============================================================================

@dataclass
class SNSContent:
    """ç¤¾äº¤å¹³å°å†…å®¹"""
    feed_id: str
    platform: str
    title: str
    content: str
    author: str
    like_count: int = 0
    comment_count: int = 0
    image_urls: List[str] = field(default_factory=list)
    xsec_token: str = ""


@dataclass
class CollectResult:
    """é‡‡é›†ç»“æœ"""
    success: bool
    fetched: int = 0
    written: int = 0
    filtered: int = 0
    duplicate: int = 0
    errors: List[str] = field(default_factory=list)
    
    def summary(self) -> str:
        status = "âœ…" if self.success else "âŒ"
        return f"{status} è·å–:{self.fetched} å†™å…¥:{self.written} è¿‡æ»¤:{self.filtered} é‡å¤:{self.duplicate}"


# ============================================================================
# æ ¸å¿ƒåŠŸèƒ½
# ============================================================================

class SNSCollector:
    """SNSå†…å®¹é‡‡é›†å™¨"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.platform = config.get("platform", {})
        self.filter_cfg = config.get("filter", {})
        self.memory_cfg = config.get("memory", {})
        self.debug = config.get("debug", {}).get("enabled", False)
        self.processing_cfg = config.get("processing", {})
        self._personality_cache: Optional[Dict[str, str]] = None
    
    def _get_personality(self) -> Dict[str, str]:
        """è·å– MaiBot äººæ ¼é…ç½®"""
        if self._personality_cache:
            return self._personality_cache
        
        try:
            from src.config.config import global_config
            # global_config.personality æ˜¯ä¸€ä¸ª PersonalityConfig å¯¹è±¡
            personality_cfg = global_config.personality
            bot_cfg = global_config.bot
            self._personality_cache = {
                "personality": getattr(personality_cfg, "personality", ""),
                "interest": getattr(personality_cfg, "interest", ""),
                "nickname": getattr(bot_cfg, "nickname", ""),
            }
        except Exception as e:
            logger.warning(f"è·å–äººæ ¼é…ç½®å¤±è´¥: {e}")
            self._personality_cache = {"personality": "", "interest": "", "nickname": ""}
        
        return self._personality_cache
    
    async def collect(self, platform: str = "xiaohongshu", keyword: Optional[str] = None, count: int = 10) -> CollectResult:
        """æ‰§è¡Œé‡‡é›†ä»»åŠ¡"""
        result = CollectResult(success=False)
        
        if self.debug:
            logger.info("=" * 60)
            logger.info(f"[SNS] ğŸš€ å¼€å§‹é‡‡é›†æµç¨‹")
            logger.info(f"[SNS]    å¹³å°: {platform}")
            logger.info(f"[SNS]    å…³é”®è¯: {keyword or '(æ¨èæµ)'}")
            logger.info(f"[SNS]    æ•°é‡: {count}")
            logger.info("=" * 60)
        
        try:
            # 1. è·å–å†…å®¹
            if self.debug:
                logger.info("[SNS] ğŸ“¥ é˜¶æ®µ1: è·å–ä¿¡æ¯æµ...")
            
            contents = await self._fetch_contents(platform, keyword, count)
            result.fetched = len(contents)
            
            if self.debug:
                logger.info(f"[SNS] âœ“ è·å–åˆ° {len(contents)} æ¡å†…å®¹")
                for i, c in enumerate(contents):
                    logger.info(f"[SNS]    [{i+1}] {c.title[:50]}{'...' if len(c.title) > 50 else ''}")
                    logger.info(f"[SNS]        ğŸ‘ {c.like_count} | ğŸ’¬ {c.comment_count} | ğŸ“ {len(c.content)}å­— | @{c.author}")
            
            if not contents:
                if self.debug:
                    logger.info("[SNS] âš ï¸ æœªè·å–åˆ°å†…å®¹ï¼Œç»“æŸ")
                result.success = True
                return result
            
            # 2. åŸºç¡€è¿‡æ»¤ï¼ˆç‚¹èµæ•°ã€é»‘ç™½åå•ï¼‰
            if self.debug:
                logger.info("-" * 60)
                logger.info("[SNS] ğŸ” é˜¶æ®µ2: åŸºç¡€è¿‡æ»¤ï¼ˆç‚¹èµæ•°/é»‘ç™½åå•ï¼‰...")
                logger.info(f"[SNS]    æœ€å°ç‚¹èµæ•°: {self.filter_cfg.get('min_like_count', 100)}")
            
            filtered = self._filter_contents(contents)
            result.filtered = result.fetched - len(filtered)
            
            if self.debug:
                logger.info(f"[SNS] âœ“ åŸºç¡€è¿‡æ»¤: {len(contents)} â†’ {len(filtered)} æ¡ï¼ˆè¿‡æ»¤ {result.filtered} æ¡ï¼‰")
            
            # 3. äººæ ¼å…´è¶£åŒ¹é…ï¼ˆLLM åˆ¤æ–­æ˜¯å¦ç¬¦åˆ MaiBot å…´è¶£ï¼‰
            if self.debug:
                logger.info("-" * 60)
                logger.info("[SNS] ğŸ§  é˜¶æ®µ3: äººæ ¼å…´è¶£åŒ¹é…...")
                personality = self._get_personality()
                logger.info(f"[SNS]    å…´è¶£é…ç½®: {personality.get('interest', '(æœªé…ç½®)')[:80]}...")
            
            before_match = len(filtered)
            filtered = await self._match_personality_interest(filtered)
            result.filtered += before_match - len(filtered)
            
            if self.debug:
                logger.info(f"[SNS] âœ“ äººæ ¼åŒ¹é…: {before_match} â†’ {len(filtered)} æ¡")
                if filtered:
                    logger.info("[SNS]    æ„Ÿå…´è¶£çš„å†…å®¹:")
                    for c in filtered:
                        logger.info(f"[SNS]      âœ“ {c.title[:40]}...")
            
            if not filtered:
                if self.debug:
                    logger.info("[SNS] âš ï¸ æ²¡æœ‰ç¬¦åˆå…´è¶£çš„å†…å®¹ï¼Œç»“æŸ")
                result.success = True
                return result
            
            # 4. è·å–è¯¦æƒ…ï¼ˆåªå¯¹æ„Ÿå…´è¶£çš„å†…å®¹è·å–å®Œæ•´æ­£æ–‡ï¼‰
            fetch_detail = self.platform.get(platform, {}).get("fetch_detail", True)
            if fetch_detail:
                if self.debug:
                    logger.info("-" * 60)
                    logger.info("[SNS] ğŸ“„ é˜¶æ®µ4: è·å–è¯¦æƒ…ï¼ˆæ­£æ–‡+å›¾ç‰‡ï¼‰...")
                filtered = await self._fetch_details(filtered, platform)
            
            # 5. å†™å…¥è®°å¿†
            if self.debug:
                logger.info("-" * 60)
                logger.info("[SNS] ğŸ’¾ é˜¶æ®µ5: å†™å…¥è®°å¿†...")
            
            for content in filtered:
                try:
                    is_dup = await self._check_duplicate(content)
                    if is_dup:
                        if self.debug:
                            logger.info(f"[SNS]    â­ï¸ è·³è¿‡é‡å¤: {content.title[:30]}...")
                        result.duplicate += 1
                        continue
                    
                    await self._write_to_memory(content, platform)
                    result.written += 1
                    if self.debug:
                        logger.info(f"[SNS]    âœ… å†™å…¥æˆåŠŸ: {content.title[:30]}...")
                        logger.info(f"[SNS]       æ­£æ–‡: {content.content[:80]}{'...' if len(content.content) > 80 else ''}")
                except Exception as e:
                    logger.error(f"[SNS]    âŒ å†™å…¥å¤±è´¥: {e}")
                    result.errors.append(f"å†™å…¥å¤±è´¥: {e}")
            
            result.success = True
            
            if self.debug:
                logger.info("=" * 60)
                logger.info(f"[SNS] ğŸ‰ é‡‡é›†å®Œæˆ!")
                logger.info(f"[SNS]    è·å–: {result.fetched} | è¿‡æ»¤: {result.filtered} | é‡å¤: {result.duplicate} | å†™å…¥: {result.written}")
                logger.info("=" * 60)
            
        except Exception as e:
            logger.error(f"é‡‡é›†å¤±è´¥: {e}")
            result.errors.append(str(e))
        
        return result
    
    async def _fetch_contents(self, platform: str, keyword: Optional[str], count: int) -> List[SNSContent]:
        """é€šè¿‡MCPå·¥å…·è·å–å†…å®¹"""
        contents = []
        result = None
        
        # è·å–MCPå·¥å…·åå‰ç¼€
        mcp_prefix = self.platform.get(platform, {}).get("mcp_server_name", platform)
        
        # è°ƒç”¨MCPå·¥å…·
        if keyword:
            tool_name = f"{mcp_prefix}_search_feeds"
        else:
            tool_name = f"{mcp_prefix}_list_feeds"
        
        if self.debug:
            logger.info(f"[SNS Debug] è°ƒç”¨å·¥å…·: {tool_name}")
        
        tool = tool_api.get_tool_instance(tool_name)
        if not tool:
            logger.warning(f"MCPå·¥å…· {tool_name} ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥MCPæ¡¥æ¥æ’ä»¶é…ç½®")
            return contents
        
        try:
            if keyword:
                result = await tool.direct_execute(keyword=keyword)
            else:
                result = await tool.direct_execute()
        except Exception as e:
            logger.error(f"è°ƒç”¨MCPå·¥å…· {tool_name} å¤±è´¥: {e}")
            return contents
        
        # è§£æç»“æœ
        content_str = result.get("content", "") if isinstance(result, dict) else str(result)
        
        if self.debug:
            # æ‰“å°åŸå§‹è¿”å›å†…å®¹ï¼ˆæˆªå–å‰2000å­—ç¬¦ï¼‰
            logger.info(f"[SNS Debug] MCPåŸå§‹è¿”å› (å‰2000å­—ç¬¦):\n{content_str[:2000]}")
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯é”™è¯¯å“åº”
        if content_str.startswith("âŒ") or content_str.startswith("âš ï¸") or content_str.startswith("â›”"):
            logger.warning(f"MCPå·¥å…·è¿”å›é”™è¯¯: {content_str[:100]}")
            return contents
        
        contents = self._parse_mcp_result(content_str, platform)
        
        return contents[:count]
    
    def _parse_mcp_result(self, result: str, platform: str) -> List[SNSContent]:
        """è§£æMCPè¿”å›ç»“æœ"""
        contents = []
        
        if not result or not result.strip():
            return contents
        
        try:
            data = json.loads(result)
            
            # æ”¯æŒå¤šç§è¿”å›æ ¼å¼
            if isinstance(data, list):
                items = data
            elif isinstance(data, dict):
                items = data.get("items", data.get("feeds", data.get("notes", data.get("data", []))))
                if not isinstance(items, list):
                    items = [data]  # å•æ¡æ•°æ®
            else:
                return contents
            
            for item in items:
                if not isinstance(item, dict):
                    continue
                
                # å°çº¢ä¹¦çš„æ•°æ®ç»“æ„: item.noteCard åŒ…å«è¯¦ç»†ä¿¡æ¯
                note_card = item.get("noteCard", {})
                user_info = note_card.get("user", {})
                interact_info = note_card.get("interactInfo", {})
                cover_info = note_card.get("cover", {})
                
                # æå–feed_id
                feed_id = str(item.get("id", item.get("note_id", "")))
                if not feed_id:
                    continue
                
                # æå–ç‚¹èµæ•°ï¼ˆä» interactInfo.likedCountï¼‰
                like_count = interact_info.get("likedCount", item.get("likedCount", 0))
                if isinstance(like_count, str):
                    # å¤„ç†å¯èƒ½çš„å°æ•°æ ¼å¼å¦‚ "1.60000"
                    like_count = int(float(like_count.replace(",", "").replace("ä¸‡", "0000") or 0))
                
                # æå–è¯„è®ºæ•°
                comment_count = interact_info.get("commentCount", item.get("commentCount", 0))
                if isinstance(comment_count, str):
                    comment_count = int(float(comment_count.replace(",", "") or 0))
                
                # æå–æ ‡é¢˜ï¼ˆä» noteCard.displayTitleï¼‰
                title = note_card.get("displayTitle", item.get("title", ""))
                
                # æå–ä½œè€…ï¼ˆä» noteCard.userï¼‰
                author = user_info.get("nickname", user_info.get("nickName", item.get("nickname", "")))
                
                # æå–å°é¢å›¾ç‰‡
                images = []
                if cover_info.get("urlDefault"):
                    images.append(cover_info["urlDefault"])
                
                contents.append(SNSContent(
                    feed_id=feed_id,
                    platform=platform,
                    title=title,
                    content=note_card.get("desc", item.get("desc", "")),
                    author=author,
                    like_count=int(like_count),
                    comment_count=int(comment_count),
                    image_urls=images,
                    xsec_token=item.get("xsecToken", ""),
                ))
                
        except json.JSONDecodeError:
            logger.debug(f"éJSONæ ¼å¼ç»“æœï¼Œé•¿åº¦={len(result)}")
        except Exception as e:
            logger.warning(f"è§£æMCPç»“æœå¤±è´¥: {e}")
        
        return contents
    
    async def _fetch_details(self, contents: List[SNSContent], platform: str) -> List[SNSContent]:
        """è·å–å†…å®¹è¯¦æƒ…ï¼ˆè¡¥å……æ­£æ–‡ï¼‰"""
        mcp_prefix = self.platform.get(platform, {}).get("mcp_server_name", platform)
        tool_name = f"{mcp_prefix}_get_feed_detail"
        
        tool = tool_api.get_tool_instance(tool_name)
        if not tool:
            if self.debug:
                logger.info(f"[SNS]    âš ï¸ è¯¦æƒ…å·¥å…· {tool_name} ä¸å­˜åœ¨ï¼Œè·³è¿‡")
            return contents
        
        if self.debug:
            logger.info(f"[SNS]    ä½¿ç”¨å·¥å…·: {tool_name}")
        
        updated = []
        for i, content in enumerate(contents):
            try:
                if self.debug:
                    logger.info(f"[SNS]    [{i+1}/{len(contents)}] è·å–: {content.title[:30]}...")
                
                result = await tool.direct_execute(
                    feed_id=content.feed_id,
                    xsec_token=content.xsec_token
                )
                
                content_str = result.get("content", "") if isinstance(result, dict) else str(result)
                
                # è§£æè¯¦æƒ…
                detail = self._parse_feed_detail(content_str)
                if detail:
                    old_len = len(content.content)
                    # æ›´æ–°æ­£æ–‡å†…å®¹
                    if detail.get("desc"):
                        content.content = detail["desc"]
                    if detail.get("images"):
                        content.image_urls = detail["images"]
                    
                    if self.debug:
                        logger.info(f"[SNS]        âœ“ æ­£æ–‡: {old_len} â†’ {len(content.content)} å­—")
                        logger.info(f"[SNS]        âœ“ å›¾ç‰‡: {len(content.image_urls)} å¼ ")
                else:
                    if self.debug:
                        logger.info(f"[SNS]        âš ï¸ è¯¦æƒ…è§£æå¤±è´¥ï¼Œä¿ç•™åŸå†…å®¹")
                
                updated.append(content)
                
            except Exception as e:
                if self.debug:
                    logger.warning(f"[SNS]        âŒ è·å–å¤±è´¥: {e}")
                updated.append(content)  # å³ä½¿å¤±è´¥ä¹Ÿä¿ç•™åŸå†…å®¹
        
        return updated
    
    def _parse_feed_detail(self, result: str) -> Optional[Dict]:
        """è§£æè¯¦æƒ…è¿”å›"""
        try:
            data = json.loads(result)
            
            # å°çº¢ä¹¦è¯¦æƒ…ç»“æ„: { feed_id, data: { note: {...}, comments: [...] } }
            # éœ€è¦ä» data.data.note ä¸­è·å–å†…å®¹
            note = None
            
            # å°è¯•å¤šç§å¯èƒ½çš„æ•°æ®è·¯å¾„
            if isinstance(data, dict):
                if "data" in data and isinstance(data["data"], dict):
                    # ç»“æ„: { data: { note: {...} } }
                    note = data["data"].get("note", {})
                elif "note" in data:
                    # ç»“æ„: { note: {...} }
                    note = data["note"]
                elif "noteCard" in data:
                    # ç»“æ„: { noteCard: {...} }
                    note = data["noteCard"]
                else:
                    # ç›´æ¥ä½¿ç”¨é¡¶å±‚
                    note = data
            
            if not note:
                if self.debug:
                    logger.warning(f"[SNS Debug] æ— æ³•æ‰¾åˆ° note æ•°æ®")
                return None
            
            if self.debug:
                logger.info(f"[SNS Debug] note keys: {list(note.keys())[:10]}")
            
            # è·å–æ­£æ–‡ - å°è¯•å¤šç§å­—æ®µå
            desc = ""
            for field in ["desc", "description", "content", "text", "noteDesc"]:
                if note.get(field):
                    desc = note[field]
                    if self.debug:
                        logger.info(f"[SNS Debug] æ‰¾åˆ°æ­£æ–‡å­—æ®µ: {field}, é•¿åº¦: {len(desc)}")
                    break
            
            # è·å–å›¾ç‰‡åˆ—è¡¨
            images = []
            image_list = note.get("imageList") or note.get("images") or note.get("image_list") or []
            
            if self.debug and image_list:
                logger.info(f"[SNS Debug] å›¾ç‰‡åˆ—è¡¨: {len(image_list)} å¼ ")
                if image_list and isinstance(image_list[0], dict):
                    logger.info(f"[SNS Debug] å›¾ç‰‡é¡¹ keys: {list(image_list[0].keys())[:5]}")
            
            for img in image_list:
                if isinstance(img, dict):
                    # å°è¯•å¤šç§ URL å­—æ®µï¼ˆä¼˜å…ˆä½¿ç”¨ urlDefaultï¼‰
                    url = ""
                    for url_field in ["urlDefault", "url_default", "url", "originUrl", "original_url", "urlPre"]:
                        if img.get(url_field):
                            url = img[url_field]
                            break
                    # å°è¯•ä» infoList è·å–
                    if not url and img.get("infoList"):
                        info_list = img["infoList"]
                        if info_list and isinstance(info_list[0], dict):
                            url = info_list[0].get("url", "")
                    if url:
                        images.append(url)
                elif isinstance(img, str):
                    images.append(img)
            
            if self.debug:
                logger.info(f"[SNS Debug] è§£æç»“æœ: descé•¿åº¦={len(desc)}, imagesæ•°é‡={len(images)}")
            
            return {
                "desc": desc,
                "images": images,
            }
        except json.JSONDecodeError as e:
            if self.debug:
                logger.warning(f"[SNS Debug] JSONè§£æå¤±è´¥: {e}, åŸå§‹å†…å®¹å‰200å­—: {result[:200]}")
            return None
        except Exception as e:
            if self.debug:
                logger.warning(f"[SNS Debug] è¯¦æƒ…è§£æå¼‚å¸¸: {e}")
            return None
    
    def _filter_contents(self, contents: List[SNSContent]) -> List[SNSContent]:
        """è¿‡æ»¤å†…å®¹"""
        min_likes = self.filter_cfg.get("min_like_count", 100)
        blacklist = self.filter_cfg.get("keyword_blacklist", [])
        whitelist = self.filter_cfg.get("keyword_whitelist", [])
        
        if self.debug:
            logger.info(f"[SNS Debug] è¿‡æ»¤é…ç½®: min_likes={min_likes}, whitelist={whitelist}, blacklist={blacklist}")
        
        filtered = []
        for c in contents:
            text = f"{c.title} {c.content}"
            
            if self.debug:
                logger.info(f"[SNS Debug] æ£€æŸ¥å†…å®¹: title={c.title[:30]}..., likes={c.like_count}")
            
            # ç™½åå•ä¼˜å…ˆä¿ç•™
            if whitelist and any(kw in text for kw in whitelist):
                if self.debug:
                    logger.info(f"[SNS Debug] âœ“ ç™½åå•å‘½ä¸­ï¼Œä¿ç•™")
                filtered.append(c)
                continue
            
            # ç‚¹èµæ•°è¿‡æ»¤
            if c.like_count < min_likes:
                if self.debug:
                    logger.info(f"[SNS Debug] âœ— ç‚¹èµæ•°ä¸è¶³: {c.like_count} < {min_likes}")
                continue
            
            # é»‘åå•è¿‡æ»¤
            if any(kw in text for kw in blacklist):
                if self.debug:
                    logger.info(f"[SNS Debug] âœ— é»‘åå•å‘½ä¸­")
                continue
            
            if self.debug:
                logger.info(f"[SNS Debug] âœ“ é€šè¿‡è¿‡æ»¤")
            filtered.append(c)
        
        return filtered
    
    async def _match_personality_interest(self, contents: List[SNSContent]) -> List[SNSContent]:
        """ä½¿ç”¨ LLM åˆ¤æ–­å†…å®¹æ˜¯å¦ç¬¦åˆ MaiBot äººæ ¼å…´è¶£"""
        if not contents:
            return []
        
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨äººæ ¼åŒ¹é…
        if not self.processing_cfg.get("enable_personality_match", False):
            if self.debug:
                logger.info("[SNS Debug] äººæ ¼åŒ¹é…æœªå¯ç”¨ï¼Œè·³è¿‡")
            return contents
        
        personality = self._get_personality()
        interest = personality.get("interest", "")
        
        if not interest:
            if self.debug:
                logger.info("[SNS Debug] æœªé…ç½®å…´è¶£ï¼Œè·³è¿‡äººæ ¼åŒ¹é…")
            return contents
        
        if self.debug:
            logger.info(f"[SNS Debug] å¼€å§‹äººæ ¼å…´è¶£åŒ¹é…ï¼Œå…´è¶£: {interest[:50]}...")
        
        # æ„å»ºå†…å®¹åˆ—è¡¨ä¾› LLM åˆ¤æ–­
        content_list = []
        for i, c in enumerate(contents):
            content_list.append(f"{i+1}. ã€{c.title}ã€‘{c.content[:100] if c.content else ''}")
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªå†…å®¹ç­›é€‰åŠ©æ‰‹ã€‚æ ¹æ®ä»¥ä¸‹äººæ ¼å…´è¶£æè¿°ï¼Œåˆ¤æ–­å“ªäº›å†…å®¹å€¼å¾—æ·±å…¥äº†è§£ã€‚

äººæ ¼å…´è¶£ï¼š{interest}

å¾…ç­›é€‰å†…å®¹ï¼š
{chr(10).join(content_list)}

è¯·è¿”å›ä½ è®¤ä¸ºç¬¦åˆè¯¥äººæ ¼å…´è¶£çš„å†…å®¹ç¼–å·ï¼Œç”¨é€—å·åˆ†éš”ã€‚
åªè¿”å›ç¼–å·ï¼Œä¾‹å¦‚ï¼š1,3,5
å¦‚æœéƒ½ä¸ç¬¦åˆï¼Œè¿”å›ï¼šæ— """

        try:
            models = llm_api.get_available_models()
            model_cfg = models.get("utils") or models.get("replyer")
            
            if not model_cfg:
                return contents
            
            success, response, _, _ = await llm_api.generate_with_model(
                prompt=prompt,
                model_config=model_cfg,
                request_type="sns_personality_match",
            )
            
            if not success or not response:
                return contents
            
            response = response.strip()
            if self.debug:
                logger.info(f"[SNS Debug] LLM å…´è¶£åŒ¹é…ç»“æœ: {response}")
            
            if response == "æ— " or not response:
                return []
            
            # è§£æç¼–å·
            matched_indices = set()
            for part in response.replace("ï¼Œ", ",").split(","):
                part = part.strip()
                if part.isdigit():
                    idx = int(part) - 1
                    if 0 <= idx < len(contents):
                        matched_indices.add(idx)
            
            matched = [contents[i] for i in sorted(matched_indices)]
            
            if self.debug:
                logger.info(f"[SNS Debug] äººæ ¼åŒ¹é…: {len(contents)} -> {len(matched)} æ¡")
                for c in matched:
                    logger.info(f"[SNS Debug]   âœ“ {c.title[:40]}...")
            
            return matched
            
        except Exception as e:
            logger.warning(f"äººæ ¼å…´è¶£åŒ¹é…å¤±è´¥: {e}")
            return contents
    
    async def _check_duplicate(self, content: SNSContent) -> bool:
        """æ£€æŸ¥æ˜¯å¦é‡å¤"""
        if not content.feed_id:
            return False
        
        # é€šè¿‡feed_idæ£€æŸ¥ï¼ˆåœ¨key_pointä¸­å­˜å‚¨äº†feed_idï¼‰
        try:
            records = await database_api.db_get(
                ChatHistory,
                filters={"chat_id": f"sns_{content.platform}"},
                limit=200,
            )
            
            if records:
                for r in records:
                    key_point = r.get("key_point", "") or ""
                    if f"feed_id:{content.feed_id}" in key_point:
                        return True
            
            return False
        except Exception as e:
            logger.warning(f"æ£€æŸ¥é‡å¤å¤±è´¥: {e}")
            return False
    
    async def _write_to_memory(self, content: SNSContent, platform: str) -> None:
        """å†™å…¥ChatHistory"""
        # ç”Ÿæˆæ‘˜è¦
        summary = await self._generate_summary(content)
        
        # å›¾ç‰‡è¯†å›¾ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        image_desc = ""
        enable_img_rec = self.processing_cfg.get("enable_image_recognition", False)
        if self.debug:
            logger.info(f"[SNS]    ğŸ“ å†™å…¥è®°å¿†: {content.title[:30]}...")
            logger.info(f"[SNS]       å›¾ç‰‡æ•°é‡: {len(content.image_urls)}")
            logger.info(f"[SNS]       è¯†å›¾å¼€å…³: {enable_img_rec}")
        
        if content.image_urls and enable_img_rec:
            image_desc = await self._recognize_images(content.image_urls[:3])
            if self.debug:
                logger.info(f"[SNS]       è¯†å›¾ç»“æœ: {image_desc[:80] if image_desc else '(æ— )'}")
        
        # æå–å…³é”®è¯
        keywords = await self._extract_keywords(content)
        
        # æ„å»ºè®°å½•
        chat_id = f"sns_{platform}"
        now = time.time()
        
        url = self._get_content_url(content)
        full_summary = f"[æ¥è‡ª{platform}] {summary}"
        if image_desc:
            full_summary += f"\n[å›¾ç‰‡å†…å®¹] {image_desc}"
        full_summary += f"\nä½œè€…: @{content.author}\nåŸæ–‡: {url}"
        
        data = {
            "chat_id": chat_id,
            "start_time": now,
            "end_time": now,
            "original_text": content.content[:500],
            "participants": json.dumps([content.author]),
            "theme": content.title or summary[:50],
            "keywords": json.dumps(keywords),
            "summary": full_summary,
            "key_point": json.dumps([f"feed_id:{content.feed_id}", f"likes:{content.like_count}"]),
        }
        
        try:
            await database_api.db_query(ChatHistory, query_type="create", data=data)
            logger.info(f"å†™å…¥SNSè®°å¿†: {content.title[:30]}...")
        except Exception as e:
            logger.error(f"å†™å…¥å¤±è´¥ï¼Œç¼“å­˜åˆ°æœ¬åœ°: {e}")
            self._cache_failed_write(data)
            raise
    
    async def _recognize_images(self, image_urls: List[str]) -> str:
        """è¯†å›¾ï¼ˆè°ƒç”¨MaiBotçš„ImageManagerï¼‰"""
        if self.debug:
            logger.info(f"[SNS] ğŸ–¼ï¸ å¼€å§‹è¯†å›¾ï¼Œå…± {len(image_urls)} å¼ å›¾ç‰‡")
        
        try:
            from src.chat.utils.utils_image import get_image_manager
            image_manager = get_image_manager()
            
            if self.debug:
                logger.info(f"[SNS]    âœ“ ImageManager åŠ è½½æˆåŠŸ")
            
            descriptions = []
            for i, url in enumerate(image_urls[:2]):  # æœ€å¤šè¯†åˆ«2å¼ 
                try:
                    if self.debug:
                        logger.info(f"[SNS]    [{i+1}] ä¸‹è½½å›¾ç‰‡: {url[:80]}...")
                    
                    # ä¸‹è½½å›¾ç‰‡å¹¶è½¬æ¢ä¸º base64
                    image_base64 = await self._download_image_as_base64(url)
                    if not image_base64:
                        if self.debug:
                            logger.info(f"[SNS]        âš ï¸ å›¾ç‰‡ä¸‹è½½å¤±è´¥")
                        continue
                    
                    if self.debug:
                        logger.info(f"[SNS]        âœ“ ä¸‹è½½æˆåŠŸï¼Œå¼€å§‹è¯†åˆ«...")
                    
                    desc = await asyncio.wait_for(
                        image_manager.get_image_description(image_base64),
                        timeout=self.processing_cfg.get("image_recognition_timeout", 30)
                    )
                    if desc:
                        descriptions.append(desc)
                        if self.debug:
                            logger.info(f"[SNS]        âœ“ è¯†åˆ«ç»“æœ: {desc[:100]}{'...' if len(desc) > 100 else ''}")
                    else:
                        if self.debug:
                            logger.info(f"[SNS]        âš ï¸ è¯†åˆ«è¿”å›ç©ºç»“æœ")
                except asyncio.TimeoutError:
                    logger.warning(f"[SNS]    âŒ è¯†å›¾è¶…æ—¶: {url[:50]}...")
                except Exception as e:
                    logger.warning(f"[SNS]    âŒ è¯†å›¾å¤±è´¥: {e}")
            
            result = "; ".join(descriptions) if descriptions else ""
            if self.debug:
                logger.info(f"[SNS]    è¯†å›¾å®Œæˆ: {len(descriptions)} å¼ æˆåŠŸ")
            return result
        except ImportError as e:
            if self.debug:
                logger.warning(f"[SNS]    âŒ ImageManager å¯¼å…¥å¤±è´¥: {e}")
            return ""
    
    async def _download_image_as_base64(self, url: str) -> Optional[str]:
        """ä¸‹è½½å›¾ç‰‡å¹¶è½¬æ¢ä¸º base64"""
        import base64
        try:
            import aiohttp
            
            timeout = aiohttp.ClientTimeout(total=15)
            async with aiohttp.ClientSession(timeout=timeout) as session:
                async with session.get(url) as response:
                    if response.status == 200:
                        image_bytes = await response.read()
                        return base64.b64encode(image_bytes).decode("utf-8")
                    else:
                        logger.warning(f"[SNS] å›¾ç‰‡ä¸‹è½½å¤±è´¥: HTTP {response.status}")
                        return None
        except Exception as e:
            logger.warning(f"[SNS] å›¾ç‰‡ä¸‹è½½å¼‚å¸¸: {e}")
            return None
    
    def _cache_failed_write(self, data: Dict) -> None:
        """ç¼“å­˜å†™å…¥å¤±è´¥çš„æ•°æ®"""
        try:
            cache = []
            if CACHE_FILE.exists():
                cache = json.loads(CACHE_FILE.read_text())
            cache.append({"data": data, "time": time.time()})
            CACHE_FILE.write_text(json.dumps(cache, ensure_ascii=False, indent=2))
        except Exception as e:
            logger.error(f"ç¼“å­˜å¤±è´¥: {e}")
    
    async def retry_cached_writes(self) -> int:
        """é‡è¯•ç¼“å­˜çš„å†™å…¥"""
        if not CACHE_FILE.exists():
            return 0
        
        try:
            cache = json.loads(CACHE_FILE.read_text())
            success = 0
            remaining = []
            
            for item in cache:
                try:
                    await database_api.db_query(ChatHistory, query_type="create", data=item["data"])
                    success += 1
                except Exception:
                    remaining.append(item)
            
            if remaining:
                CACHE_FILE.write_text(json.dumps(remaining, ensure_ascii=False, indent=2))
            else:
                CACHE_FILE.unlink()
            
            logger.info(f"é‡è¯•ç¼“å­˜å†™å…¥: æˆåŠŸ{success}æ¡, å‰©ä½™{len(remaining)}æ¡")
            return success
        except Exception as e:
            logger.error(f"é‡è¯•ç¼“å­˜å¤±è´¥: {e}")
            return 0
    
    async def _generate_summary(self, content: SNSContent) -> str:
        """ç”Ÿæˆæ‘˜è¦"""
        text = f"{content.title}\n{content.content}"
        
        if len(text) < 200:
            return text
        
        # ä½¿ç”¨LLMç”Ÿæˆæ‘˜è¦
        try:
            models = llm_api.get_available_models()
            model_cfg = models.get("utils") or models.get("replyer")
            
            if model_cfg:
                prompt = f"è¯·ç”¨ä¸€ä¸¤å¥è¯æ¦‚æ‹¬ä»¥ä¸‹å†…å®¹çš„æ ¸å¿ƒä¿¡æ¯ï¼š\n\n{text[:1000]}"
                success, summary, _, _ = await llm_api.generate_with_model(
                    prompt=prompt,
                    model_config=model_cfg,
                    request_type="sns_summary",
                )
                if success and summary:
                    return summary.strip()
        except Exception as e:
            logger.warning(f"LLMæ‘˜è¦å¤±è´¥: {e}")
        
        # é™çº§ï¼šæˆªæ–­
        return text[:200] + "..."
    
    async def _extract_keywords(self, content: SNSContent) -> List[str]:
        """æå–å…³é”®è¯"""
        keywords = []
        
        # ä»æ ‡é¢˜æå–ï¼ˆæŒ‰ç©ºæ ¼å’Œæ ‡ç‚¹åˆ†è¯ï¼‰
        if content.title:
            import re
            words = re.split(r'[\s,ï¼Œã€‚ï¼ï¼Ÿ!?ã€]+', content.title)
            keywords.extend([w for w in words if len(w) >= 2][:3])
        
        # æ·»åŠ ä½œè€…å
        if content.author:
            keywords.append(content.author)
        
        # æ·»åŠ å¹³å°æ ‡è¯†
        keywords.append(content.platform)
        
        # å»é‡å¹¶é™åˆ¶æ•°é‡
        seen = set()
        unique = []
        for kw in keywords:
            if kw and kw not in seen:
                seen.add(kw)
                unique.append(kw)
        
        return unique[:8]
    
    def _get_content_url(self, content: SNSContent) -> str:
        """è·å–å†…å®¹URL"""
        if content.platform == "xiaohongshu":
            return f"https://xiaohongshu.com/explore/{content.feed_id}"
        return ""
    
    async def cleanup(self, days: int = 30, max_records: int = 1000) -> Tuple[int, int]:
        """æ¸…ç†æ—§è®°å¿†"""
        deleted = 0
        checked = 0
        
        # è·å–SNSè®°å¿†
        records = await database_api.db_get(
            ChatHistory,
            filters={},
            order_by="-start_time",
            limit=max_records + 100,
        )
        
        if not records:
            return checked, deleted
        
        # ç­›é€‰SNSè®°å¿†
        sns_records = [r for r in records if str(r.get("chat_id", "")).startswith("sns_")]
        checked = len(sns_records)
        
        # æŒ‰æ—¶é—´æ¸…ç†
        cutoff = time.time() - days * 86400
        for r in sns_records:
            if r.get("start_time", 0) < cutoff:
                await database_api.db_query(
                    ChatHistory,
                    query_type="delete",
                    filters={"id": r["id"]},
                )
                deleted += 1
        
        # æŒ‰æ•°é‡æ¸…ç†
        if len(sns_records) - deleted > max_records:
            to_delete = sns_records[max_records:]
            for r in to_delete:
                if r["id"] not in [x["id"] for x in sns_records[:max_records]]:
                    await database_api.db_query(
                        ChatHistory,
                        query_type="delete",
                        filters={"id": r["id"]},
                    )
                    deleted += 1
        
        logger.info(f"SNSè®°å¿†æ¸…ç†: æ£€æŸ¥{checked}æ¡, åˆ é™¤{deleted}æ¡")
        return checked, deleted


# ============================================================================
# Dreamå·¥å…· - ä¾›åšæ¢¦æ¨¡å—è°ƒç”¨
# ============================================================================

class SNSCollectTool(BaseTool):
    """ç¤¾äº¤å¹³å°é‡‡é›†å·¥å…·"""
    
    name = "collect_sns_content"
    description = "ä»ç¤¾äº¤å¹³å°ï¼ˆå¦‚å°çº¢ä¹¦ï¼‰é‡‡é›†çƒ­é—¨å†…å®¹å¹¶å†™å…¥è®°å¿†ã€‚åœ¨åšæ¢¦æ—¶å¯ä»¥è°ƒç”¨æ­¤å·¥å…·å­¦ä¹ æ–°çŸ¥è¯†ã€‚"
    parameters = [
        ("platform", ToolParamType.STRING, "å¹³å°åç§°ï¼Œé»˜è®¤xiaohongshu", False, ["xiaohongshu"]),
        ("keyword", ToolParamType.STRING, "æœç´¢å…³é”®è¯ï¼ˆå¯é€‰ï¼‰", False, None),
        ("count", ToolParamType.INTEGER, "é‡‡é›†æ•°é‡ï¼Œé»˜è®¤5", False, None),
    ]
    available_for_llm = False  # ä¸åœ¨å›å¤æ—¶è°ƒç”¨ï¼Œåªä¾›åšæ¢¦æ¨¡å—ä½¿ç”¨
    
    async def execute(self, function_args: dict) -> dict:
        platform = function_args.get("platform", "xiaohongshu")
        keyword = function_args.get("keyword")
        count = int(function_args.get("count", 5))
        
        collector = SNSCollector(_get_config())
        result = await collector.collect(platform, keyword, count)
        
        return {"name": self.name, "content": result.summary()}
    
    async def direct_execute(self, **kwargs) -> dict:
        return await self.execute(kwargs)


class SNSCleanupTool(BaseTool):
    """ç¤¾äº¤å¹³å°è®°å¿†æ¸…ç†å·¥å…·"""
    
    name = "cleanup_sns_memory"
    description = "æ¸…ç†è¿‡æœŸçš„ç¤¾äº¤å¹³å°è®°å¿†ï¼Œä¿æŒè®°å¿†åº“æ•´æ´ã€‚"
    parameters = [
        ("days", ToolParamType.INTEGER, "æ¸…ç†å¤šå°‘å¤©å‰çš„è®°å¿†ï¼Œé»˜è®¤30", False, None),
    ]
    available_for_llm = False  # ä¸åœ¨å›å¤æ—¶è°ƒç”¨ï¼Œåªä¾›åšæ¢¦æ¨¡å—ä½¿ç”¨
    
    async def execute(self, function_args: dict) -> dict:
        days = int(function_args.get("days", 30))
        
        collector = SNSCollector(_get_config())
        checked, deleted = await collector.cleanup(days)
        
        return {"name": self.name, "content": f"æ£€æŸ¥{checked}æ¡ï¼Œåˆ é™¤{deleted}æ¡è¿‡æœŸè®°å¿†"}
    
    async def direct_execute(self, **kwargs) -> dict:
        return await self.execute(kwargs)


# ============================================================================
# å‘½ä»¤å¤„ç†å™¨
# ============================================================================

class SNSCommand(BaseCommand):
    """SNSå‘½ä»¤"""
    
    command_name = "sns_command"
    command_description = "ç¤¾äº¤å¹³å°é‡‡é›†å‘½ä»¤"
    command_pattern = r"^[/ï¼]sns(?:\s+(?P<action>collect|search|status|cleanup|config|dream))?(?:\s+(?P<arg>.+))?$"
    
    async def execute(self) -> Tuple[bool, str, bool]:
        action = self.matched_groups.get("action", "collect")
        arg = self.matched_groups.get("arg", "")
        
        config = _get_config()
        collector = SNSCollector(config)
        
        if action == "collect":
            result = await collector.collect()
            await self.send_text(f"SNSé‡‡é›†å®Œæˆ\n{result.summary()}")
        
        elif action == "dream":
            # æ¨¡æ‹Ÿåšæ¢¦å¼é‡‡é›†ï¼šå¸¦äººæ ¼å…´è¶£åŒ¹é…çš„é‡‡é›†
            await self.send_text("ğŸŒ™ å¼€å§‹åšæ¢¦å¼é‡‡é›†ï¼ˆå¸¦äººæ ¼å…´è¶£åŒ¹é…ï¼‰...")
            
            # å¼ºåˆ¶å¼€å¯äººæ ¼åŒ¹é…
            dream_config = dict(config)
            if "processing" not in dream_config:
                dream_config["processing"] = {}
            dream_config["processing"]["enable_personality_match"] = True
            
            dream_collector = SNSCollector(dream_config)
            result = await dream_collector.collect(count=15)  # å¤šè·å–ä¸€äº›ï¼Œè®© LLM ç­›é€‰
            
            await self.send_text(f"ğŸŒ™ åšæ¢¦é‡‡é›†å®Œæˆ\n{result.summary()}")
            
        elif action == "search":
            if not arg:
                await self.send_text("è¯·æä¾›æœç´¢å…³é”®è¯ï¼Œä¾‹å¦‚: /sns search æ—…æ¸¸æ”»ç•¥")
                return True, "ç¼ºå°‘å…³é”®è¯", True
            result = await collector.collect(keyword=arg)
            await self.send_text(f"SNSæœç´¢ã€Œ{arg}ã€å®Œæˆ\n{result.summary()}")
            
        elif action == "cleanup":
            days = int(arg) if arg.isdigit() else 30
            checked, deleted = await collector.cleanup(days)
            await self.send_text(f"SNSæ¸…ç†å®Œæˆ: æ£€æŸ¥{checked}æ¡, åˆ é™¤{deleted}æ¡")
            
        elif action == "status":
            records = await database_api.db_get(ChatHistory, limit=1000)
            sns_records = [r for r in (records or []) if str(r.get("chat_id", "")).startswith("sns_")]
            
            # æŒ‰å¹³å°ç»Ÿè®¡
            by_platform = {}
            for r in sns_records:
                p = r.get("chat_id", "").replace("sns_", "")
                by_platform[p] = by_platform.get(p, 0) + 1
            
            status = f"SNSè®°å¿†ç»Ÿè®¡: å…±{len(sns_records)}æ¡\n"
            for p, c in by_platform.items():
                status += f"  - {p}: {c}æ¡\n"
            await self.send_text(status)
            
        elif action == "config":
            cfg = config
            config_info = (
                f"SNSé…ç½®:\n"
                f"  æœ€å°ç‚¹èµæ•°: {cfg.get('filter', {}).get('min_like_count', 100)}\n"
                f"  æœ€å¤§è®°å½•æ•°: {cfg.get('memory', {}).get('max_records', 1000)}\n"
                f"  è‡ªåŠ¨æ¸…ç†: {cfg.get('memory', {}).get('auto_cleanup_days', 30)}å¤©\n"
                f"  è¯†å›¾åŠŸèƒ½: {'å¼€å¯' if cfg.get('processing', {}).get('enable_image_recognition') else 'å…³é—­'}"
            )
            await self.send_text(config_info)
            
        else:
            await self.send_text("ç”¨æ³•: /sns [collect|search <å…³é”®è¯>|status|cleanup|config|dream]")
        
        return True, "å‘½ä»¤æ‰§è¡Œå®Œæˆ", True


# ============================================================================
# å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨
# ============================================================================

class SNSScheduler:
    """å®šæ—¶é‡‡é›†è°ƒåº¦å™¨"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.running = False
        self._task: Optional[asyncio.Task] = None
        self._lock = asyncio.Lock()
    
    async def start(self) -> None:
        """å¯åŠ¨è°ƒåº¦å™¨"""
        if self.running:
            return
        
        self.running = True
        interval = self.config.get("scheduler", {}).get("interval_minutes", 60) * 60
        
        if interval <= 0:
            logger.info("SNSå®šæ—¶ä»»åŠ¡å·²ç¦ç”¨")
            return
        
        self._task = asyncio.create_task(self._run_loop(interval))
        logger.info(f"SNSå®šæ—¶ä»»åŠ¡å¯åŠ¨ï¼Œé—´éš”{interval // 60}åˆ†é’Ÿ")
    
    async def stop(self) -> None:
        """åœæ­¢è°ƒåº¦å™¨"""
        self.running = False
        if self._task:
            self._task.cancel()
            try:
                await self._task
            except asyncio.CancelledError:
                pass
        logger.info("SNSå®šæ—¶ä»»åŠ¡å·²åœæ­¢")
    
    async def _run_loop(self, interval: float) -> None:
        """å®šæ—¶æ‰§è¡Œå¾ªç¯"""
        # é¦–æ¬¡å»¶è¿Ÿ
        first_delay = self.config.get("scheduler", {}).get("first_delay_minutes", 5) * 60
        await asyncio.sleep(first_delay)
        
        while self.running:
            async with self._lock:  # é˜²æ­¢å¹¶å‘
                try:
                    collector = SNSCollector(self.config)
                    
                    # é‡è¯•ç¼“å­˜çš„å†™å…¥
                    await collector.retry_cached_writes()
                    
                    # æ‰§è¡Œé‡‡é›†
                    tasks = self.config.get("scheduler", {}).get("tasks", [])
                    if not tasks:
                        tasks = [{"platform": "xiaohongshu"}]
                    
                    for task in tasks:
                        if not task.get("enabled", True):
                            continue
                        result = await collector.collect(
                            platform=task.get("platform", "xiaohongshu"),
                            keyword=task.get("keyword"),
                            count=task.get("count", 10),
                        )
                        logger.info(f"å®šæ—¶é‡‡é›†å®Œæˆ: {result.summary()}")
                    
                except Exception as e:
                    logger.error(f"å®šæ—¶é‡‡é›†å¤±è´¥: {e}")
            
            await asyncio.sleep(interval)


# å…¨å±€å®ä¾‹
_scheduler: Optional[SNSScheduler] = None
_plugin_instance: Optional["MaiBotSNSPlugin"] = None


def _get_config() -> Dict[str, Any]:
    """è·å–æ’ä»¶é…ç½®"""
    global _plugin_instance
    if _plugin_instance and hasattr(_plugin_instance, "config"):
        return _plugin_instance.config
    return {}


def _register_dream_tools() -> None:
    """æ³¨å†Œ SNS å·¥å…·åˆ°åšæ¢¦æ¨¡å—"""
    try:
        from src.dream.dream_agent import get_dream_tool_registry, DreamTool
        from src.llm_models.payload_content.tool_option import ToolParamType
        
        registry = get_dream_tool_registry()
        
        # åˆ›å»º SNS é‡‡é›†å·¥å…·çš„æ‰§è¡Œå‡½æ•°
        async def collect_sns_content(platform: str = "xiaohongshu", keyword: str = "", count: int = 10) -> str:
            """æ‰§è¡Œ SNS é‡‡é›†"""
            config = _get_config()
            # å¼ºåˆ¶å¼€å¯äººæ ¼åŒ¹é…
            if "processing" not in config:
                config["processing"] = {}
            config["processing"]["enable_personality_match"] = True
            
            collector = SNSCollector(config)
            result = await collector.collect(
                platform=platform,
                keyword=keyword if keyword else None,
                count=int(count)
            )
            return f"SNSé‡‡é›†å®Œæˆ: {result.summary()}"
        
        # æ³¨å†Œé‡‡é›†å·¥å…·
        registry.register_tool(
            DreamTool(
                name="collect_sns_content",
                description="ä»ç¤¾äº¤å¹³å°ï¼ˆå¦‚å°çº¢ä¹¦ï¼‰é‡‡é›†å†…å®¹å¹¶å†™å…¥è®°å¿†ã€‚ä¼šæ ¹æ®ä½ çš„å…´è¶£è‡ªåŠ¨ç­›é€‰å†…å®¹ï¼Œåªä¿ç•™æ„Ÿå…´è¶£çš„ä¿¡æ¯ã€‚é€‚åˆåœ¨åšæ¢¦æ—¶å­¦ä¹ æ–°çŸ¥è¯†ã€äº†è§£çƒ­é—¨è¯é¢˜ã€‚",
                parameters=[
                    ("platform", ToolParamType.STRING, "å¹³å°åç§°ï¼Œç›®å‰æ”¯æŒ xiaohongshuï¼ˆå°çº¢ä¹¦ï¼‰", False, None),
                    ("keyword", ToolParamType.STRING, "æœç´¢å…³é”®è¯ï¼ˆå¯é€‰ï¼‰ï¼Œç•™ç©ºåˆ™è·å–æ¨èå†…å®¹", False, None),
                    ("count", ToolParamType.INTEGER, "è·å–æ•°é‡ï¼Œé»˜è®¤10ï¼Œå»ºè®®5-20", False, None),
                ],
                execute_func=collect_sns_content,
            )
        )
        
        logger.info("[SNS] âœ“ å·²æ³¨å†Œ Dream å·¥å…·: collect_sns_content")
        
    except ImportError as e:
        logger.debug(f"[SNS] åšæ¢¦æ¨¡å—æœªåŠ è½½ï¼Œè·³è¿‡ Dream å·¥å…·æ³¨å†Œ: {e}")
    except Exception as e:
        logger.warning(f"[SNS] æ³¨å†Œ Dream å·¥å…·å¤±è´¥: {e}")


def _register_memory_retrieval_tools() -> None:
    """æ³¨å†Œ SNS è®°å¿†æœç´¢å·¥å…·åˆ°è®°å¿†æ£€ç´¢ç³»ç»Ÿ"""
    logger.info("[SNS] å¼€å§‹æ³¨å†Œè®°å¿†æ£€ç´¢å·¥å…·...")
    try:
        from src.memory_system.retrieval_tools import register_memory_retrieval_tool
        logger.info("[SNS] æˆåŠŸå¯¼å…¥ register_memory_retrieval_tool")
        
        async def search_sns_memory(chat_id: str, keyword: Optional[str] = None) -> str:
            """æœç´¢ SNS è®°å¿†ï¼ˆç¤¾äº¤å¹³å°é‡‡é›†çš„å†…å®¹ï¼‰"""
            if not keyword:
                return "è¯·æä¾›æœç´¢å…³é”®è¯"
            
            try:
                # ç›´æ¥æŸ¥è¯¢æ•°æ®åº“ä¸­çš„ SNS è®°å½•
                records = await database_api.db_get(
                    ChatHistory,
                    filters={},
                    order_by="-start_time",
                    limit=100,
                )
                
                if not records:
                    return "æœªæ‰¾åˆ°ä»»ä½• SNS è®°å¿†"
                
                # ç­›é€‰ SNS è®°å½•å¹¶åŒ¹é…å…³é”®è¯
                keywords_lower = [kw.lower().strip() for kw in keyword.split() if kw.strip()]
                matched = []
                
                for r in records:
                    # åªæœç´¢ SNS è®°å½•
                    if not str(r.get("chat_id", "")).startswith("sns_"):
                        continue
                    
                    # åœ¨ themeã€summaryã€keywords ä¸­æœç´¢
                    theme = (r.get("theme") or "").lower()
                    summary = (r.get("summary") or "").lower()
                    record_keywords = (r.get("keywords") or "").lower()
                    
                    # æ£€æŸ¥æ˜¯å¦åŒ¹é…ä»»ä¸€å…³é”®è¯
                    for kw in keywords_lower:
                        if kw in theme or kw in summary or kw in record_keywords:
                            matched.append(r)
                            break
                
                if not matched:
                    return f"æœªæ‰¾åˆ°åŒ…å«å…³é”®è¯ã€Œ{keyword}ã€çš„ SNS è®°å¿†"
                
                # æ„å»ºç»“æœ
                results = []
                for r in matched[:10]:  # æœ€å¤šè¿”å›10æ¡
                    platform = r.get("chat_id", "").replace("sns_", "")
                    results.append(
                        f"è®°å¿†IDï¼š{r.get('id')}\n"
                        f"æ¥æºï¼š{platform}\n"
                        f"ä¸»é¢˜ï¼š{r.get('theme', '(æ— )')}\n"
                        f"å…³é”®è¯ï¼š{r.get('keywords', '(æ— )')}"
                    )
                
                return f"æ‰¾åˆ° {len(matched)} æ¡ SNS è®°å¿†ï¼ˆæ˜¾ç¤ºå‰{len(results)}æ¡ï¼‰ï¼š\n\n" + "\n\n---\n\n".join(results)
                
            except Exception as e:
                logger.error(f"æœç´¢ SNS è®°å¿†å¤±è´¥: {e}")
                return f"æœç´¢å¤±è´¥: {e}"
        
        async def get_sns_memory_detail(chat_id: str, memory_ids: str) -> str:
            """è·å– SNS è®°å¿†è¯¦æƒ…"""
            try:
                # è§£æ ID åˆ—è¡¨
                id_list = [int(id_str.strip()) for id_str in memory_ids.split(",") if id_str.strip().isdigit()]
                if not id_list:
                    return "è¯·æä¾›æœ‰æ•ˆçš„è®°å¿†ID"
                
                # æŸ¥è¯¢è®°å½•ï¼ˆä¸é™åˆ¶ chat_idï¼Œæ”¯æŒè·¨èŠå¤©æµè·å– SNS è®°å¿†ï¼‰
                records = await database_api.db_get(
                    ChatHistory,
                    filters={},
                    limit=500,
                )
                
                # ç­›é€‰åŒ¹é…çš„è®°å½•
                matched = [r for r in (records or []) if r.get("id") in id_list]
                
                if not matched:
                    return f"æœªæ‰¾åˆ°IDä¸º {id_list} çš„è®°å¿†"
                
                # æ„å»ºè¯¦æƒ…
                results = []
                for r in matched:
                    parts = [
                        f"è®°å¿†IDï¼š{r.get('id')}",
                        f"æ¥æºï¼š{r.get('chat_id', '').replace('sns_', '')}",
                        f"ä¸»é¢˜ï¼š{r.get('theme', '(æ— )')}",
                    ]
                    if r.get("summary"):
                        parts.append(f"æ¦‚æ‹¬ï¼š{r.get('summary')}")
                    if r.get("keywords"):
                        parts.append(f"å…³é”®è¯ï¼š{r.get('keywords')}")
                    results.append("\n".join(parts))
                
                return "\n\n" + "=" * 50 + "\n\n".join(results)
                
            except Exception as e:
                logger.error(f"è·å– SNS è®°å¿†è¯¦æƒ…å¤±è´¥: {e}")
                return f"è·å–å¤±è´¥: {e}"
        
        # æ³¨å†Œæœç´¢å·¥å…·
        register_memory_retrieval_tool(
            name="search_sns_memory",
            description="æœç´¢ä»å°çº¢ä¹¦ç­‰ç¤¾äº¤å¹³å°é‡‡é›†çš„å¤–éƒ¨çŸ¥è¯†è®°å¿†ã€‚é€‚ç”¨äºæŸ¥æ‰¾ï¼šäº§å“èµ„è®¯ï¼ˆå¦‚XREALã€æ‰‹æœºã€ç›¸æœºï¼‰ã€ç§‘æŠ€æ•°ç ã€AIå·¥å…·ã€æ¸¸æˆåŠ¨æ¼«ã€çƒ­é—¨è¯é¢˜ç­‰ã€‚å½“search_chat_historyæ‰¾ä¸åˆ°ä¿¡æ¯æ—¶ï¼Œå¯ä»¥å°è¯•æ­¤å·¥å…·æœç´¢å¤–éƒ¨æ¥æºçš„çŸ¥è¯†ã€‚",
            parameters=[
                {"name": "keyword", "type": "string", "description": "æœç´¢å…³é”®è¯ï¼ˆå¦‚ï¼šXREALã€Tanvasã€AIã€æ‰‹æœºã€æ¸¸æˆç­‰ï¼‰", "required": True},
            ],
            execute_func=search_sns_memory,
        )
        
        # æ³¨å†Œè¯¦æƒ…å·¥å…·
        register_memory_retrieval_tool(
            name="get_sns_memory_detail",
            description="è·å–ç¤¾äº¤å¹³å°è®°å¿†çš„è¯¦ç»†å†…å®¹ã€‚éœ€è¦å…ˆä½¿ç”¨ search_sns_memory è·å–è®°å¿†IDã€‚",
            parameters=[
                {"name": "memory_ids", "type": "string", "description": "è®°å¿†IDï¼Œå¯ä»¥æ˜¯å•ä¸ªIDæˆ–å¤šä¸ªIDï¼ˆé€—å·åˆ†éš”ï¼‰", "required": True},
            ],
            execute_func=get_sns_memory_detail,
        )
        
        logger.info("[SNS] âœ“ å·²æ³¨å†Œè®°å¿†æ£€ç´¢å·¥å…·: search_sns_memory, get_sns_memory_detail")
        
    except ImportError as e:
        logger.debug(f"[SNS] è®°å¿†æ£€ç´¢æ¨¡å—æœªåŠ è½½ï¼Œè·³è¿‡å·¥å…·æ³¨å†Œ: {e}")
    except Exception as e:
        logger.warning(f"[SNS] æ³¨å†Œè®°å¿†æ£€ç´¢å·¥å…·å¤±è´¥: {e}")


# ============================================================================
# äº‹ä»¶å¤„ç†å™¨
# ============================================================================

class SNSStartupHandler(BaseEventHandler):
    """æ’ä»¶å¯åŠ¨äº‹ä»¶å¤„ç†"""
    
    event_type = EventType.ON_START
    handler_name = "sns_startup_handler"
    handler_description = "SNSæ’ä»¶å¯åŠ¨å¤„ç†å™¨"
    weight = 0
    intercept_message = False
    
    async def execute(self, message: Optional[Any]) -> Tuple[bool, bool, Optional[str], None, None]:
        global _scheduler
        
        logger.info("MaiBot_SNS æ’ä»¶å¯åŠ¨")
        
        config = _get_config()
        
        # æ³¨å†Œ Dream å·¥å…·ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if config.get("dream", {}).get("enabled", True):
            _register_dream_tools()
        
        # æ³¨å†Œè®°å¿†æ£€ç´¢å·¥å…·ï¼ˆè®© MaiBot å›å¿†æ—¶èƒ½æœç´¢ SNS è®°å¿†ï¼‰
        _register_memory_retrieval_tools()
        
        # å¯åŠ¨å®šæ—¶è°ƒåº¦å™¨
        if config.get("scheduler", {}).get("enabled", False):
            _scheduler = SNSScheduler(config)
            await _scheduler.start()
        
        return (True, True, None, None, None)


class SNSShutdownHandler(BaseEventHandler):
    """æ’ä»¶åœæ­¢äº‹ä»¶å¤„ç†"""
    
    event_type = EventType.ON_STOP
    handler_name = "sns_shutdown_handler"
    handler_description = "SNSæ’ä»¶åœæ­¢å¤„ç†å™¨"
    weight = 0
    intercept_message = False
    
    async def execute(self, message: Optional[Any]) -> Tuple[bool, bool, Optional[str], None, None]:
        global _scheduler
        
        logger.info("MaiBot_SNS æ’ä»¶åœæ­¢")
        
        if _scheduler:
            await _scheduler.stop()
            _scheduler = None
        
        return (True, True, None, None, None)


# ============================================================================
# æ’ä»¶ä¸»ç±»
# ============================================================================

@register_plugin
class MaiBotSNSPlugin(BasePlugin):
    """MaiBot SNSæ’ä»¶"""
    
    plugin_name = "maibot_sns"
    enable_plugin = True
    dependencies = ["mcp_bridge_plugin"]
    python_dependencies = []
    config_file_name = "config.toml"
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        global _plugin_instance
        _plugin_instance = self
    
    config_schema = {
        "plugin": {
            "name": ConfigField(type=str, default="maibot_sns", description="æ’ä»¶åç§°"),
            "version": ConfigField(type=str, default="1.0.0", description="ç‰ˆæœ¬"),
            "enabled": ConfigField(type=bool, default=True, description="æ˜¯å¦å¯ç”¨"),
        },
        "platform": {
            "xiaohongshu": {
                "enabled": ConfigField(type=bool, default=True, description="å¯ç”¨å°çº¢ä¹¦"),
                "mcp_server_name": ConfigField(type=str, default="xiaohongshu", description="MCPæœåŠ¡å™¨å"),
            },
        },
        "filter": {
            "min_like_count": ConfigField(type=int, default=100, description="æœ€å°ç‚¹èµæ•°"),
            "keyword_whitelist": ConfigField(type=list, default=[], description="å…³é”®è¯ç™½åå•ï¼ˆä¼˜å…ˆä¿ç•™ï¼‰"),
            "keyword_blacklist": ConfigField(type=list, default=[], description="å…³é”®è¯é»‘åå•"),
        },
        "processing": {
            "enable_summary": ConfigField(type=bool, default=True, description="å¯ç”¨LLMæ‘˜è¦"),
            "summary_threshold": ConfigField(type=int, default=200, description="æ‘˜è¦è§¦å‘é•¿åº¦"),
            "enable_image_recognition": ConfigField(type=bool, default=False, description="å¯ç”¨å›¾ç‰‡è¯†åˆ«"),
            "image_recognition_timeout": ConfigField(type=int, default=30, description="è¯†å›¾è¶…æ—¶(ç§’)"),
        },
        "memory": {
            "max_records": ConfigField(type=int, default=1000, description="æœ€å¤§è®°å½•æ•°"),
            "auto_cleanup_days": ConfigField(type=int, default=30, description="è‡ªåŠ¨æ¸…ç†å¤©æ•°"),
        },
        "scheduler": {
            "enabled": ConfigField(type=bool, default=False, description="å¯ç”¨å®šæ—¶é‡‡é›†"),
            "interval_minutes": ConfigField(type=int, default=60, description="é‡‡é›†é—´éš”(åˆ†é’Ÿ)"),
            "first_delay_minutes": ConfigField(type=int, default=5, description="é¦–æ¬¡å»¶è¿Ÿ(åˆ†é’Ÿ)"),
        },
    }
    
    def get_plugin_components(self) -> List[Tuple[ComponentInfo, Type]]:
        """æ³¨å†Œç»„ä»¶"""
        return [
            (SNSCollectTool.get_tool_info(), SNSCollectTool),
            (SNSCleanupTool.get_tool_info(), SNSCleanupTool),
            (SNSCommand.get_command_info(), SNSCommand),
            (SNSStartupHandler.get_handler_info(), SNSStartupHandler),
            (SNSShutdownHandler.get_handler_info(), SNSShutdownHandler),
        ]
